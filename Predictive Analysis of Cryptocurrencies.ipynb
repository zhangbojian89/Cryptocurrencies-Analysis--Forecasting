{"cells":[{"cell_type":"markdown","metadata":{"papermill":{"duration":0.132445,"end_time":"2022-05-24T12:30:02.708771","exception":false,"start_time":"2022-05-24T12:30:02.576326","status":"completed"},"tags":[]},"source":["<a class=\"anchor\" id=\"0\"></a>\n","# Predictive Analysis of Cryptocurrencies"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.126395,"end_time":"2022-05-24T12:30:03.741907","exception":false,"start_time":"2022-05-24T12:30:03.615512","status":"completed"},"tags":[]},"source":["<a class=\"anchor\" id=\"0.1\"></a>\n","\n","## Table of Contents\n","\n","1. [Import libraries and set parameters](#1)\n","1. [Download data](#2)\n","1. [EDA](#3)\n","   - [3.1 Market Cap](#3.1)\n","   - [3.2 Cryptocurrency data](#3.2)\n","   - [3.3 Cryptocurrency features data](#3.3)\n","   - [3.4 Stationarity check](#3.4)\n","   - [3.5 Identification of seasonality](#3.5)\n","   - [3.6 EDA with Pandas Profiling Report](#3.6)   \n","1. [FE](#4)\n","   - [4.1 FE with TSFRESH](#4.1)\n","   - [4.2 FE from technical features (Finance knowledge and Data Science)](#4.2)\n","   - [4.3 Analysis of anomalies](#4.3)\n","       - [4.3.1 Analysis of anomalies for \"Close\"](#4.3.1)\n","       - [4.3.2 Analysis of anomalies for the first data difference \"Close_diff\"](#4.3.2)\n","   - [4.4 Analysis of the impact of COVID-19 on the cryptocurrency rate](#4.4)\n","   - [4.5 Get target, training, validation and test datasets for ML models](#4.5)\n","1. [Model training and forecasting](#5)\n","    - [5.1 Facebook Prophet](#5.1)\n","    - [5.2 ARIMA](#5.2)\n","        - [5.2.1 How to find the order of differencing (d) in ARIMA model](#5.2.1)\n","        - [5.2.2 How to find the order of the AR term (p)](#5.2.2)\n","        - [5.2.3 How to find the order of the MA term (q)](#5.2.3)\n","        - [5.2.4 How to build the ARIMA Model with manually defined parameters](#5.2.4)\n","        - [5.2.5 How to build the ARIMA automatically](#5.2.5)\n","    - [5.3 Other ML models (Multi-factors models)](#5.3)\n","        - [5.3.1 Set parameters for many models](#5.3.1)\n","        - [5.3.2 Models training and forecasting](#5.3.2)\n","    - [5.4 Choosing the main optimal model and forecasting](#5.4)\n","    - [5.5 Feature importance study](#5.5)    "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.12714,"end_time":"2022-05-24T12:30:03.996004","exception":false,"start_time":"2022-05-24T12:30:03.868864","status":"completed"},"tags":[]},"source":["## 1. Import libraries and set parameters <a class=\"anchor\" id=\"1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:12.952135Z","iopub.status.busy":"2022-06-08T12:56:12.951481Z","iopub.status.idle":"2022-06-08T12:56:20.559271Z","shell.execute_reply":"2022-06-08T12:56:20.558398Z","shell.execute_reply.started":"2022-06-08T12:56:12.951958Z"},"papermill":{"duration":13.959932,"end_time":"2022-05-24T12:30:18.084895","exception":false,"start_time":"2022-05-24T12:30:04.124963","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Import libraries\n","import random\n","import os\n","import numpy as np \n","import pandas as pd \n","import requests\n","import pandas_datareader as web\n","\n","# Date\n","import datetime as dt\n","from datetime import date, timedelta, datetime\n","\n","# EDA\n","import matplotlib.pyplot as plt\n","from matplotlib.pylab import rcParams\n","import plotly.express as px\n","import plotly.graph_objects as go\n","from plotly.offline import init_notebook_mode\n","init_notebook_mode(connected=True)\n","import pandas_profiling as pp\n","\n","# FE\n","from tsfresh import extract_features, select_features, extract_relevant_features\n","from tsfresh.utilities.dataframe_functions import impute\n","from sklearn.inspection import permutation_importance\n","import eli5\n","from eli5.sklearn import PermutationImportance\n","import shap\n","\n","# Time Series - EDA and Modelling\n","import statsmodels.api as sm\n","from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n","from statsmodels.tsa.stattools import adfuller\n","from statsmodels.tsa.seasonal import seasonal_decompose\n","from statsmodels.tsa.arima_model import ARIMA\n","\n","# Metrics\n","from sklearn.metrics import r2_score\n","from sklearn.metrics import mean_squared_error, mean_absolute_percentage_error\n","\n","# Modeling and preprocessing\n","from sklearn.preprocessing import StandardScaler, MinMaxScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.linear_model import LinearRegression\n","from sklearn.svm import SVR, LinearSVR\n","from sklearn.neighbors import KNeighborsRegressor\n","from sklearn.ensemble import RandomForestRegressor\n","from sklearn.ensemble import BaggingRegressor, AdaBoostRegressor\n","from sklearn.neural_network import MLPRegressor\n","from prophet import Prophet\n","import xgboost as xgb\n","from xgboost import XGBRegressor\n","import lightgbm as lgb\n","from lightgbm import LGBMRegressor\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:20.561258Z","iopub.status.busy":"2022-06-08T12:56:20.560889Z","iopub.status.idle":"2022-06-08T12:56:20.564709Z","shell.execute_reply":"2022-06-08T12:56:20.564096Z","shell.execute_reply.started":"2022-06-08T12:56:20.561227Z"},"trusted":true},"outputs":[],"source":["# What EDA & FE techniques use?\n","is_EDA_with_Pandas_Profiling = True # or False - Get Pandas Profiling Report or no?\n","is_EDA_with_COVID19_data = True # or False - Make EDA with COVID-19 data or no?\n","is_anomalies = True # or False - Take into account anomalies or no?"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:20.566064Z","iopub.status.busy":"2022-06-08T12:56:20.565832Z","iopub.status.idle":"2022-06-08T12:56:20.583763Z","shell.execute_reply":"2022-06-08T12:56:20.582741Z","shell.execute_reply.started":"2022-06-08T12:56:20.566035Z"},"trusted":true},"outputs":[],"source":["# What type of model to use?\n","is_Prophet = True   # or False - Facebook Prophet\n","is_ARIMA = True     # or False - ARIMA and AutoARIMA\n","is_other_ML = True  # or False - multi-factors models: trees, neural networks, etc."]},{"cell_type":"code","execution_count":null,"metadata":{"_kg_hide-output":true,"execution":{"iopub.execute_input":"2022-06-08T12:56:20.586361Z","iopub.status.busy":"2022-06-08T12:56:20.585618Z","iopub.status.idle":"2022-06-08T12:56:31.661476Z","shell.execute_reply":"2022-06-08T12:56:31.660437Z","shell.execute_reply.started":"2022-06-08T12:56:20.586314Z"},"papermill":{"duration":14.809239,"end_time":"2022-05-24T12:30:33.024434","exception":false,"start_time":"2022-05-24T12:30:18.215195","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Automatic building ARIMA for Time Series\n","if is_ARIMA:\n","    !pip install pmdarima\n","    import pmdarima as pm"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.663492Z","iopub.status.busy":"2022-06-08T12:56:31.663135Z","iopub.status.idle":"2022-06-08T12:56:31.669506Z","shell.execute_reply":"2022-06-08T12:56:31.668598Z","shell.execute_reply.started":"2022-06-08T12:56:31.663445Z"},"papermill":{"duration":0.143151,"end_time":"2022-05-24T12:30:33.30189","exception":false,"start_time":"2022-05-24T12:30:33.158739","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Set random state\n","def fix_all_seeds(seed):\n","    np.random.seed(seed)\n","    random.seed(seed)\n","    os.environ['PYTHONHASHSEED'] = str(seed)\n","\n","random_state = 42\n","fix_all_seeds(random_state)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.133996,"end_time":"2022-05-24T12:30:33.572091","exception":false,"start_time":"2022-05-24T12:30:33.438095","status":"completed"},"tags":[]},"source":["**TASK:** It is proposed to experiment with forecasting_days"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.670799Z","iopub.status.busy":"2022-06-08T12:56:31.670507Z","iopub.status.idle":"2022-06-08T12:56:31.683421Z","shell.execute_reply":"2022-06-08T12:56:31.682437Z","shell.execute_reply.started":"2022-06-08T12:56:31.670766Z"},"papermill":{"duration":0.146281,"end_time":"2022-05-24T12:30:33.85259","exception":false,"start_time":"2022-05-24T12:30:33.706309","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Set main parameters\n","cryptocurrency = 'BTC'\n","target = 'Close'\n","forecasting_days = 10  # forecasting_days > 1"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.138977,"end_time":"2022-05-24T12:30:34.130496","exception":false,"start_time":"2022-05-24T12:30:33.991519","status":"completed"},"tags":[]},"source":["**TASK :** It is proposed to experiment with date_start and date_end"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.685761Z","iopub.status.busy":"2022-06-08T12:56:31.685425Z","iopub.status.idle":"2022-06-08T12:56:31.698991Z","shell.execute_reply":"2022-06-08T12:56:31.698075Z","shell.execute_reply.started":"2022-06-08T12:56:31.685718Z"},"papermill":{"duration":0.147461,"end_time":"2022-05-24T12:30:34.419384","exception":false,"start_time":"2022-05-24T12:30:34.271923","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Set time interval of data for given cryptocurrency - the period of coronavirus in 2020-2021\n","date_start = dt.datetime(2020, 4, 1)\n","# date_end = dt.datetime.now()\n","date_end = dt.datetime(2021, 12, 31)\n","print(f\"Time interval: from {date_start} to {date_end}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.141527,"end_time":"2022-05-24T12:30:34.989295","exception":false,"start_time":"2022-05-24T12:30:34.847768","status":"completed"},"tags":[]},"source":["## 2. Download data <a class=\"anchor\" id=\"2\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.701213Z","iopub.status.busy":"2022-06-08T12:56:31.700364Z","iopub.status.idle":"2022-06-08T12:56:31.7561Z","shell.execute_reply":"2022-06-08T12:56:31.755222Z","shell.execute_reply.started":"2022-06-08T12:56:31.701172Z"},"papermill":{"duration":0.196135,"end_time":"2022-05-24T12:30:35.319106","exception":false,"start_time":"2022-05-24T12:30:35.122971","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Download information about cryptocurrencies\n","df_about = pd.read_csv(\"../input/forecasting-top-cryptocurrencies/about_top_cryptocurrencies_1B_information.csv\", sep=\";\")\n","display(df_about)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.758111Z","iopub.status.busy":"2022-06-08T12:56:31.757791Z","iopub.status.idle":"2022-06-08T12:56:31.762939Z","shell.execute_reply":"2022-06-08T12:56:31.76227Z","shell.execute_reply.started":"2022-06-08T12:56:31.758061Z"},"papermill":{"duration":0.144021,"end_time":"2022-05-24T12:30:35.604764","exception":false,"start_time":"2022-05-24T12:30:35.460743","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_part_number(x):\n","    # Get 1 - st, 2 - nd, 3 - rd, 4.. - th in the first, second, third, ...\n","    if x==1:\n","        return 'st'\n","    elif x==2:\n","        return 'nd'\n","    elif x==3:\n","        return 'rd'\n","    else: return 'th'"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.765863Z","iopub.status.busy":"2022-06-08T12:56:31.765507Z","iopub.status.idle":"2022-06-08T12:56:31.779321Z","shell.execute_reply":"2022-06-08T12:56:31.778469Z","shell.execute_reply.started":"2022-06-08T12:56:31.765834Z"},"papermill":{"duration":0.157326,"end_time":"2022-05-24T12:30:35.897345","exception":false,"start_time":"2022-05-24T12:30:35.740019","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_rank_cryptocurrency(cryptocurrency):\n","    # Get rank by Market Cap for code of the cryptocurrency\n","    # Download the dataset from https://coinmarketcap.com/currencies/bitcoin/\n","    \n","    place = df_about.index[df_about['code'] == cryptocurrency].tolist()[0]\n","    print(f\"{df_about.loc[place, 'name']} was {place+1}{get_part_number(place+1)}\",\n","          \"among the world's cryptocurrencies by market capitalization (2022-04-11)\")\n","    \n","# Get rank by Market Cap of the cryptocurrency\n","get_rank_cryptocurrency(cryptocurrency)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:31.780787Z","iopub.status.busy":"2022-06-08T12:56:31.780534Z","iopub.status.idle":"2022-06-08T12:56:33.028935Z","shell.execute_reply":"2022-06-08T12:56:33.028059Z","shell.execute_reply.started":"2022-06-08T12:56:31.780758Z"},"papermill":{"duration":1.481439,"end_time":"2022-05-24T12:30:37.520875","exception":false,"start_time":"2022-05-24T12:30:36.039436","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_data(cryptocurrency, date_start, date_end=None):\n","    # Get data for given cryptocurrency in USD from Yahoo.finance and https://coinmarketcap.com/\n","    # date_end = None means that the date_end is the current day\n","    \n","    if date_end is None:\n","        date_end = dt.datetime.now()\n","    df = web.DataReader(f'{cryptocurrency}-USD', 'yahoo', date_start, date_end)\n","    \n","    return df\n","\n","# Download data of the cryptocurrency via API\n","df = get_data(cryptocurrency, date_start, date_end)\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.030569Z","iopub.status.busy":"2022-06-08T12:56:33.03032Z","iopub.status.idle":"2022-06-08T12:56:33.045891Z","shell.execute_reply":"2022-06-08T12:56:33.044973Z","shell.execute_reply.started":"2022-06-08T12:56:33.03053Z"},"papermill":{"duration":0.167405,"end_time":"2022-05-24T12:30:37.827295","exception":false,"start_time":"2022-05-24T12:30:37.65989","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Correlation coefficients\n","df.corr()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.048099Z","iopub.status.busy":"2022-06-08T12:56:33.047622Z","iopub.status.idle":"2022-06-08T12:56:33.062778Z","shell.execute_reply":"2022-06-08T12:56:33.062128Z","shell.execute_reply.started":"2022-06-08T12:56:33.048054Z"},"papermill":{"duration":0.164383,"end_time":"2022-05-24T12:30:38.128402","exception":false,"start_time":"2022-05-24T12:30:37.964019","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Correlation coefficients\n","df.corr()['Close']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.064671Z","iopub.status.busy":"2022-06-08T12:56:33.063872Z","iopub.status.idle":"2022-06-08T12:56:33.08611Z","shell.execute_reply":"2022-06-08T12:56:33.085262Z","shell.execute_reply.started":"2022-06-08T12:56:33.064621Z"},"papermill":{"duration":0.160392,"end_time":"2022-05-24T12:30:38.425378","exception":false,"start_time":"2022-05-24T12:30:38.264986","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df = df.drop(columns = [\"Adj Close\"])\n","df"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.137986,"end_time":"2022-05-24T12:30:38.700498","exception":false,"start_time":"2022-05-24T12:30:38.562512","status":"completed"},"tags":[]},"source":["## 3. EDA <a class=\"anchor\" id=\"3\"></a>\n","\n","[Back to Table of Contents](#0.1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.14128,"end_time":"2022-05-24T12:30:38.984508","exception":false,"start_time":"2022-05-24T12:30:38.843228","status":"completed"},"tags":[]},"source":["### 3.1. Market Cap <a class=\"anchor\" id=\"3.1\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.087594Z","iopub.status.busy":"2022-06-08T12:56:33.087356Z","iopub.status.idle":"2022-06-08T12:56:33.152926Z","shell.execute_reply":"2022-06-08T12:56:33.152018Z","shell.execute_reply.started":"2022-06-08T12:56:33.087563Z"},"papermill":{"duration":0.472086,"end_time":"2022-05-24T12:30:39.594811","exception":false,"start_time":"2022-05-24T12:30:39.122725","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Market Cap\n","crypto = pd.Series(df_about.market_cap.head(20).tolist(), index=df_about.name.head(20).tolist(), name=\"Market capitalization\")\n","crypto.plot.pie(figsize=(10, 10))"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.142638,"end_time":"2022-05-24T12:30:39.882275","exception":false,"start_time":"2022-05-24T12:30:39.739637","status":"completed"},"tags":[]},"source":["### 3.2. Cryptocurrency data <a class=\"anchor\" id=\"3.2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.154831Z","iopub.status.busy":"2022-06-08T12:56:33.154381Z","iopub.status.idle":"2022-06-08T12:56:33.194388Z","shell.execute_reply":"2022-06-08T12:56:33.193516Z","shell.execute_reply.started":"2022-06-08T12:56:33.154799Z"},"papermill":{"duration":0.437771,"end_time":"2022-05-24T12:30:40.462417","exception":false,"start_time":"2022-05-24T12:30:40.024646","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df['Close'].plot(grid=True, figsize=(12,8))"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.144438,"end_time":"2022-05-24T12:30:40.750889","exception":false,"start_time":"2022-05-24T12:30:40.606451","status":"completed"},"tags":[]},"source":["### 3.3. Cryptocurrency features data <a class=\"anchor\" id=\"3.3\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.196032Z","iopub.status.busy":"2022-06-08T12:56:33.195789Z","iopub.status.idle":"2022-06-08T12:56:33.212241Z","shell.execute_reply":"2022-06-08T12:56:33.211593Z","shell.execute_reply.started":"2022-06-08T12:56:33.196Z"},"papermill":{"duration":0.165314,"end_time":"2022-05-24T12:30:41.060151","exception":false,"start_time":"2022-05-24T12:30:40.894837","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["display(df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.213937Z","iopub.status.busy":"2022-06-08T12:56:33.213238Z","iopub.status.idle":"2022-06-08T12:56:33.225734Z","shell.execute_reply":"2022-06-08T12:56:33.224952Z","shell.execute_reply.started":"2022-06-08T12:56:33.213883Z"},"papermill":{"duration":0.158829,"end_time":"2022-05-24T12:30:41.366393","exception":false,"start_time":"2022-05-24T12:30:41.207564","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def c_chart(data,label):\n","\n","    candlestick = go.Figure(data = [go.Candlestick(x=data.index,\n","                                                   open = data['Open'], \n","                                                   high = data['High'], \n","                                                   low = data['Low'], \n","                                                   close = data['Close'])])\n","    candlestick.update_xaxes(title_text = 'Time',\n","                             rangeslider_visible = True)\n","\n","    candlestick.update_layout(\n","    title = {\n","            'text': '{:} Candelstick Chart'.format(label),\n","            \"y\":0.8,\n","            \"x\":0.5,\n","            'xanchor': 'center',\n","            'yanchor': 'top'})\n","\n","    candlestick.update_yaxes(title_text = 'Price in USD', ticksuffix = '$')\n","    return candlestick"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.228569Z","iopub.status.busy":"2022-06-08T12:56:33.227389Z","iopub.status.idle":"2022-06-08T12:56:33.313071Z","shell.execute_reply":"2022-06-08T12:56:33.312445Z","shell.execute_reply.started":"2022-06-08T12:56:33.228464Z"},"papermill":{"duration":0.308145,"end_time":"2022-05-24T12:30:41.819038","exception":false,"start_time":"2022-05-24T12:30:41.510893","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%matplotlib inline\n","btc_candle=c_chart(df, label=\"BTC Price\")\n","btc_candle.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.162225,"end_time":"2022-05-24T12:30:42.143496","exception":false,"start_time":"2022-05-24T12:30:41.981271","status":"completed"},"tags":[]},"source":["### 3.4. Stationarity check <a class=\"anchor\" id=\"3.4\"></a>\n","\n","Thanks to [Time Series: Interpreting ACF and PACF](https://www.kaggle.com/code/iamleonie/time-series-interpreting-acf-and-pacf)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.16254,"end_time":"2022-05-24T12:30:42.468158","exception":false,"start_time":"2022-05-24T12:30:42.305618","status":"completed"},"tags":[]},"source":["ACF and PACF assume stationarity of the underlying time series.\n","Staionarity can be checked by performing an **Augmented Dickey-Fuller (ADF) test**:\n","\n","> - p-value > 0.05: Fail to reject the null hypothesis (H0), the data has a unit root and is non-stationary.\n","> - p-value <= 0.05: Reject the null hypothesis (H0), the data does not have a unit root and is stationary.\n",">\n","> [...] We can see that our [ADF] statistic value [...] is less than the value [...] at 1%.\n","This suggests that we can reject the null hypothesis with a significance level of less than 1% (i.e. a low probability that the result is a statistical fluke).\n","Rejecting the null hypothesis means that the process has no unit root, and in turn that the time series is stationary or does not have time-dependent structure. - [Machine Learning Mastery: How to Check if Time Series Data is Stationary with Python](https://machinelearningmastery.com/time-series-data-stationary-python/)\n","\n","If the time series is stationary, continue to the next steps.\n","**If the time series is not stationary, try differencing the time series** and check its stationarity again.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.31479Z","iopub.status.busy":"2022-06-08T12:56:33.314087Z","iopub.status.idle":"2022-06-08T12:56:33.320692Z","shell.execute_reply":"2022-06-08T12:56:33.319993Z","shell.execute_reply.started":"2022-06-08T12:56:33.314757Z"},"papermill":{"duration":0.181482,"end_time":"2022-05-24T12:30:42.811901","exception":false,"start_time":"2022-05-24T12:30:42.630419","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def check_stationarity(series):\n","    # Thanks to https://machinelearningmastery.com/time-series-data-stationary-python/\n","\n","    result = adfuller(series.values)\n","\n","    print('ADF Statistic: %f' % result[0])\n","    print('p-value: %f' % result[1])\n","    print('Critical Values:')\n","    for key, value in result[4].items():\n","        print('\\t%s: %.3f' % (key, value))\n","\n","    if (result[1] <= 0.05) & (result[4]['5%'] > result[0]):\n","        print(\"\\u001b[32mStationary\\u001b[0m\")\n","    else:\n","        print(\"\\x1b[31mNon-stationary\\x1b[0m\")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.322058Z","iopub.status.busy":"2022-06-08T12:56:33.321734Z","iopub.status.idle":"2022-06-08T12:56:33.350109Z","shell.execute_reply":"2022-06-08T12:56:33.349496Z","shell.execute_reply.started":"2022-06-08T12:56:33.32203Z"},"papermill":{"duration":0.206532,"end_time":"2022-05-24T12:30:43.186037","exception":false,"start_time":"2022-05-24T12:30:42.979505","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Stationarity check\n","check_stationarity(df['Close'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.351556Z","iopub.status.busy":"2022-06-08T12:56:33.351278Z","iopub.status.idle":"2022-06-08T12:56:33.373536Z","shell.execute_reply":"2022-06-08T12:56:33.372584Z","shell.execute_reply.started":"2022-06-08T12:56:33.351524Z"},"papermill":{"duration":0.205936,"end_time":"2022-05-24T12:30:43.606988","exception":false,"start_time":"2022-05-24T12:30:43.401052","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Stationarity check of the first difference of time series\n","check_stationarity(df['Close'].diff().dropna())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.375438Z","iopub.status.busy":"2022-06-08T12:56:33.375014Z","iopub.status.idle":"2022-06-08T12:56:33.400651Z","shell.execute_reply":"2022-06-08T12:56:33.399548Z","shell.execute_reply.started":"2022-06-08T12:56:33.37539Z"},"papermill":{"duration":0.210011,"end_time":"2022-05-24T12:30:44.060186","exception":false,"start_time":"2022-05-24T12:30:43.850175","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Stationarity check of the second difference of time series\n","check_stationarity(df['Close'].diff().diff().dropna())"]},{"cell_type":"markdown","metadata":{"execution":{"iopub.execute_input":"2022-05-19T06:54:31.590261Z","iopub.status.busy":"2022-05-19T06:54:31.589933Z","iopub.status.idle":"2022-05-19T06:54:31.596124Z","shell.execute_reply":"2022-05-19T06:54:31.594909Z","shell.execute_reply.started":"2022-05-19T06:54:31.590231Z"},"papermill":{"duration":0.164844,"end_time":"2022-05-24T12:30:44.441139","exception":false,"start_time":"2022-05-24T12:30:44.276295","status":"completed"},"tags":[]},"source":["Therefore, it is necessary to model the first difference of the series:"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.403084Z","iopub.status.busy":"2022-06-08T12:56:33.402193Z","iopub.status.idle":"2022-06-08T12:56:33.428479Z","shell.execute_reply":"2022-06-08T12:56:33.42757Z","shell.execute_reply.started":"2022-06-08T12:56:33.403028Z"},"papermill":{"duration":0.193057,"end_time":"2022-05-24T12:30:44.79792","exception":false,"start_time":"2022-05-24T12:30:44.604863","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df['Close_diff'] = df['Close'].diff()\n","df = df.dropna()\n","df"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.167909,"end_time":"2022-05-24T12:30:45.131795","exception":false,"start_time":"2022-05-24T12:30:44.963886","status":"completed"},"tags":[]},"source":["### 3.5. Identification of seasonality <a class=\"anchor\" id=\"3.5\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:33.43074Z","iopub.status.busy":"2022-06-08T12:56:33.429884Z","iopub.status.idle":"2022-06-08T12:56:34.363666Z","shell.execute_reply":"2022-06-08T12:56:34.362709Z","shell.execute_reply.started":"2022-06-08T12:56:33.430688Z"},"papermill":{"duration":1.227249,"end_time":"2022-05-24T12:30:46.524741","exception":false,"start_time":"2022-05-24T12:30:45.297492","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get seasonality of the time series\n","decomp = seasonal_decompose(df.Close)\n","fig = decomp.plot()\n","fig.set_size_inches((12, 10))\n","fig.tight_layout()\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:34.366244Z","iopub.status.busy":"2022-06-08T12:56:34.365628Z","iopub.status.idle":"2022-06-08T12:56:35.266635Z","shell.execute_reply":"2022-06-08T12:56:35.265665Z","shell.execute_reply.started":"2022-06-08T12:56:34.366197Z"},"papermill":{"duration":1.023122,"end_time":"2022-05-24T12:30:47.721944","exception":false,"start_time":"2022-05-24T12:30:46.698822","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get seasonality of last months (Dec 2021) of the time series\n","decomposition = seasonal_decompose(df.tail(30).Close)\n","fig = decomposition.plot()\n","fig.set_size_inches((12, 10))\n","fig.tight_layout()\n","plt.grid(True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.174842,"end_time":"2022-05-24T12:30:48.072399","exception":false,"start_time":"2022-05-24T12:30:47.897557","status":"completed"},"tags":[]},"source":["There is a weekly seasonality, but its contribution is very small, so it can be neglected."]},{"cell_type":"markdown","metadata":{},"source":["### 3.6. EDA with Pandas Profiling Report <a class=\"anchor\" id=\"3.6\"></a>\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:35.268195Z","iopub.status.busy":"2022-06-08T12:56:35.267939Z","iopub.status.idle":"2022-06-08T12:56:52.667646Z","shell.execute_reply":"2022-06-08T12:56:52.666535Z","shell.execute_reply.started":"2022-06-08T12:56:35.268164Z"},"trusted":true},"outputs":[],"source":["%%time\n","if is_EDA_with_Pandas_Profiling:\n","    profile = df.profile_report(title='Pandas Profiling Report for dataset')\n","    profile.to_file(output_file=\"profile.html\")\n","    display(profile)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.173393,"end_time":"2022-05-24T12:30:48.77597","exception":false,"start_time":"2022-05-24T12:30:48.602577","status":"completed"},"tags":[]},"source":["## 4. FE <a class=\"anchor\" id=\"4\"></a>\n","\n","[Back to Table of Contents](#0.1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.178749,"end_time":"2022-05-24T12:30:49.128528","exception":false,"start_time":"2022-05-24T12:30:48.949779","status":"completed"},"tags":[]},"source":["### 4.1. FE with TSFRESH<a class=\"anchor\" id=\"4.1\"></a>\n","\n","[Back to Table of Contents](#0.1)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:52.675166Z","iopub.status.busy":"2022-06-08T12:56:52.674703Z","iopub.status.idle":"2022-06-08T12:56:52.683502Z","shell.execute_reply":"2022-06-08T12:56:52.682431Z","shell.execute_reply.started":"2022-06-08T12:56:52.675116Z"},"papermill":{"duration":0.189711,"end_time":"2022-05-24T12:30:49.492978","exception":false,"start_time":"2022-05-24T12:30:49.303267","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_tsfresh_features(data):\n","    # Get statistic features using library TSFRESH \n","    \n","    data = data.reset_index(drop=False).reset_index(drop=False)\n","    \n","    # Extract features\n","    extracted_features = extract_features(data, column_id=\"Date\", column_sort=\"Date\")\n","    \n","    # Drop features with NaN\n","    extracted_features_clean = extracted_features.dropna(axis=1, how='all').reset_index(drop=True)\n","    \n","    # Drop features with constants\n","    cols_std_zero  = []\n","    for col in extracted_features_clean.columns:\n","        if extracted_features_clean[col].std()==0:\n","            cols_std_zero.append(col)\n","    extracted_features_clean = extracted_features_clean.drop(columns = cols_std_zero)\n","\n","    extracted_features_clean['Date'] = data['Date']   # For the merging\n","    \n","    return extracted_features_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:56:52.684992Z","iopub.status.busy":"2022-06-08T12:56:52.684712Z","iopub.status.idle":"2022-06-08T12:57:10.141701Z","shell.execute_reply":"2022-06-08T12:57:10.14049Z","shell.execute_reply.started":"2022-06-08T12:56:52.684926Z"},"papermill":{"duration":26.259328,"end_time":"2022-05-24T12:31:15.929546","exception":false,"start_time":"2022-05-24T12:30:49.670218","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%time\n","# FE with TSFRESH\n","extracted_features_clean = get_tsfresh_features(df[['Close']])\n","extracted_features_clean"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.143919Z","iopub.status.busy":"2022-06-08T12:57:10.143199Z","iopub.status.idle":"2022-06-08T12:57:10.53318Z","shell.execute_reply":"2022-06-08T12:57:10.532051Z","shell.execute_reply.started":"2022-06-08T12:57:10.143876Z"},"papermill":{"duration":0.322935,"end_time":"2022-05-24T12:31:16.43151","exception":false,"start_time":"2022-05-24T12:31:16.108575","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["extracted_features_clean.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.534812Z","iopub.status.busy":"2022-06-08T12:57:10.534557Z","iopub.status.idle":"2022-06-08T12:57:10.541697Z","shell.execute_reply":"2022-06-08T12:57:10.540734Z","shell.execute_reply.started":"2022-06-08T12:57:10.53478Z"},"papermill":{"duration":0.219833,"end_time":"2022-05-24T12:31:16.833007","exception":false,"start_time":"2022-05-24T12:31:16.613174","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Extracted features by TSFRESH with cleaning\n","extracted_features_clean.columns.tolist()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.543884Z","iopub.status.busy":"2022-06-08T12:57:10.543579Z","iopub.status.idle":"2022-06-08T12:57:10.589788Z","shell.execute_reply":"2022-06-08T12:57:10.588918Z","shell.execute_reply.started":"2022-06-08T12:57:10.543844Z"},"papermill":{"duration":0.24411,"end_time":"2022-05-24T12:31:17.270009","exception":false,"start_time":"2022-05-24T12:31:17.025899","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get all features\n","df = pd.merge(df, extracted_features_clean, how='left', on='Date')\n","df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.591873Z","iopub.status.busy":"2022-06-08T12:57:10.591389Z","iopub.status.idle":"2022-06-08T12:57:10.598172Z","shell.execute_reply":"2022-06-08T12:57:10.597313Z","shell.execute_reply.started":"2022-06-08T12:57:10.591831Z"},"papermill":{"duration":0.202982,"end_time":"2022-05-24T12:31:17.672194","exception":false,"start_time":"2022-05-24T12:31:17.469212","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["df.shape"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.186367,"end_time":"2022-05-24T12:31:18.04802","exception":false,"start_time":"2022-05-24T12:31:17.861653","status":"completed"},"tags":[]},"source":["### 4.2. FE from technical features (Finance knowledge and Data Science)<a class=\"anchor\" id=\"4.2\"></a>\n","\n","[Back to Table of Contents](#0.1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.181823,"end_time":"2022-05-24T12:31:18.42092","exception":false,"start_time":"2022-05-24T12:31:18.239097","status":"completed"},"tags":[]},"source":["The description of these features and more complex options are described in the scientific paper **Mokin V.B., etc.\"Information Technology for the Cryptocurrency Rate Forecasting on the Basics of Complex Feature Engineering\". [Visnyk VPI](https://visnyk.vntu.edu.ua/index.php/visnyk). No 2 (2022).**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.600968Z","iopub.status.busy":"2022-06-08T12:57:10.600603Z","iopub.status.idle":"2022-06-08T12:57:10.610732Z","shell.execute_reply":"2022-06-08T12:57:10.609859Z","shell.execute_reply.started":"2022-06-08T12:57:10.600922Z"},"papermill":{"duration":0.205598,"end_time":"2022-05-24T12:31:18.813824","exception":false,"start_time":"2022-05-24T12:31:18.608226","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_add_features(df_feat):\n","    # FE for data as row of DataFrame\n","    \n","    # Two new features from the competition tutorial\n","    df_feat['Upper_Shadow'] = df_feat['High'] - np.maximum(df_feat['Close'], df_feat['Open'])\n","    df_feat['Lower_Shadow'] = np.minimum(df_feat['Close'], df_feat['Open']) - df_feat['Low']\n","    \n","    # Thanks to https://www.kaggle.com/code1110/gresearch-simple-lgb-starter\n","    df_feat['lower_shadow'] = np.minimum(df_feat['Close'], df_feat['Open']) - df_feat['Low']\n","    df_feat['high2low'] = (df_feat['High'] / df_feat['Low']).replace([np.inf, -np.inf, np.nan], 0.)\n","    \n","    return df_feat"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.186931,"end_time":"2022-05-24T12:31:19.193777","exception":false,"start_time":"2022-05-24T12:31:19.006846","status":"completed"},"tags":[]},"source":["**TASK :** It is proposed to experiment with FE : add new features and modify existing ones"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.61282Z","iopub.status.busy":"2022-06-08T12:57:10.612332Z","iopub.status.idle":"2022-06-08T12:57:10.667047Z","shell.execute_reply":"2022-06-08T12:57:10.666193Z","shell.execute_reply.started":"2022-06-08T12:57:10.612777Z"},"papermill":{"duration":0.233568,"end_time":"2022-05-24T12:31:19.611721","exception":false,"start_time":"2022-05-24T12:31:19.378153","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# FE - add features\n","df = get_add_features(df)\n","df"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.190615,"end_time":"2022-05-24T12:31:20.424785","exception":false,"start_time":"2022-05-24T12:31:20.23417","status":"completed"},"tags":[]},"source":["### 4.3. Analysis of anomalies<a class=\"anchor\" id=\"4.3\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.192206,"end_time":"2022-05-24T12:31:20.810891","exception":false,"start_time":"2022-05-24T12:31:20.618685","status":"completed"},"tags":[]},"source":["#### 4.3.1. Analysis of anomalies for \"Close\"<a class=\"anchor\" id=\"4.3.1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.669056Z","iopub.status.busy":"2022-06-08T12:57:10.668437Z","iopub.status.idle":"2022-06-08T12:57:10.810454Z","shell.execute_reply":"2022-06-08T12:57:10.809541Z","shell.execute_reply.started":"2022-06-08T12:57:10.669011Z"},"papermill":{"duration":0.512583,"end_time":"2022-05-24T12:31:21.510154","exception":false,"start_time":"2022-05-24T12:31:20.997571","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Drawing plot with Plotly\n","if is_anomalies:\n","    fig = px.line(df, x=\"Date\", y=\"Close\", \n","                  title=f\"Investigation of dates of anomalous changes in the cryptocurrency rate\", \n","                  log_y=False,template='gridon',width=800, height=600)\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.8121Z","iopub.status.busy":"2022-06-08T12:57:10.81186Z","iopub.status.idle":"2022-06-08T12:57:10.831696Z","shell.execute_reply":"2022-06-08T12:57:10.830767Z","shell.execute_reply.started":"2022-06-08T12:57:10.81207Z"},"papermill":{"duration":0.298523,"end_time":"2022-05-24T12:31:22.03914","exception":false,"start_time":"2022-05-24T12:31:21.740617","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Synthesis dataframe with anomalous dates for Facebook Prophet\n","if is_anomalies:\n","    anomalous_dates = ['2022-01-08', '2022-01-27', '2022-04-13', '2022-07-20',\n","                       '2022-09-06', '2022-09-29', '2022-11-08', '2022-12-17']\n","    holidays_df = pd.DataFrame(columns = ['ds', 'lower_window', 'upper_window', 'prior_scale'])\n","    holidays_df['ds'] = anomalous_dates\n","    holidays_df['holiday'] = 'anomalous_dates'\n","    holidays_df['lower_window'] = 0\n","    holidays_df['upper_window'] = 0\n","    holidays_df['prior_scale'] = 10\n","    display(holidays_df)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.833399Z","iopub.status.busy":"2022-06-08T12:57:10.833063Z","iopub.status.idle":"2022-06-08T12:57:10.844729Z","shell.execute_reply":"2022-06-08T12:57:10.843998Z","shell.execute_reply.started":"2022-06-08T12:57:10.833365Z"},"papermill":{"duration":0.282732,"end_time":"2022-05-24T12:31:22.573293","exception":false,"start_time":"2022-05-24T12:31:22.290561","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def plot_with_anomalies(df, cols_y_list, cols_y_list_name, dates_x, anomalous_dates, log_y=False):\n","    # Draws a plot with title - the features cols_y_list (y) and dates_x (x) from the dataframe df\n","    # and with vertical lines in the dates from the list anomalous_dates\n","    # with the length between the minimum and maximum of feature cols_y_list[0]\n","    # with log_y = False or True\n","    # cols_y_list - dictionary of the names of cols from cols_y_list (keys - name of feature, value - it's name for the plot legend), \n","    # name of cols_y_list[0] is the title of the all plot\n","    \n","    fig = px.line(df, x=dates_x, y=cols_y_list[0], title=cols_y_list_name[cols_y_list[0]], log_y=log_y, template='gridon',width=800, height=600)\n","    y_max = df[cols_y_list[0]].max()\n","    for i in range(len(cols_y_list)-1):\n","        fig.add_trace(go.Scatter(x=df[dates_x], y=df[cols_y_list[i+1]], mode='lines', name=cols_y_list_name[cols_y_list[i+1]]))\n","        max_i = df[cols_y_list[i+1]].max()\n","        y_max = max_i if max_i > y_max else y_max\n","    \n","    y_min = min(df[cols_y_list[0]].min(),0)\n","    for i in range(len(anomalous_dates)):\n","        anomal_date = anomalous_dates[i]\n","        #print(anomal_date, y_min, y_max)\n","        fig.add_shape(dict(type=\"line\", x0=anomal_date, y0=y_min, x1=anomal_date, y1=y_max, line=dict(color=\"red\", width=1)))\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.846046Z","iopub.status.busy":"2022-06-08T12:57:10.845768Z","iopub.status.idle":"2022-06-08T12:57:10.937967Z","shell.execute_reply":"2022-06-08T12:57:10.93726Z","shell.execute_reply.started":"2022-06-08T12:57:10.846013Z"},"papermill":{"duration":0.389032,"end_time":"2022-05-24T12:31:23.217076","exception":false,"start_time":"2022-05-24T12:31:22.828044","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Draw plot\n","if is_anomalies:\n","    plot_with_anomalies(df, [\"Close\"], \n","                        {\"Close\" : f\"Anomalous dates for {cryptocurrency}\"}, \n","                        'Date', anomalous_dates, False)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.258144,"end_time":"2022-05-24T12:31:23.739227","exception":false,"start_time":"2022-05-24T12:31:23.481083","status":"completed"},"tags":[]},"source":["If we simulate the first data difference \"Close_diff\", then other anomalies will be added, when not just an unexpected change, but when it was very large."]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.262338,"end_time":"2022-05-24T12:31:24.272921","exception":false,"start_time":"2022-05-24T12:31:24.010583","status":"completed"},"tags":[]},"source":["#### 4.3.2. Analysis of anomalies for the first data difference \"Close_diff\"<a class=\"anchor\" id=\"4.3.2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:10.939924Z","iopub.status.busy":"2022-06-08T12:57:10.939095Z","iopub.status.idle":"2022-06-08T12:57:11.000704Z","shell.execute_reply":"2022-06-08T12:57:10.999776Z","shell.execute_reply.started":"2022-06-08T12:57:10.939886Z"},"papermill":{"duration":0.374752,"end_time":"2022-05-24T12:31:25.020943","exception":false,"start_time":"2022-05-24T12:31:24.646191","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Drawing plot with Plotly\n","if is_anomalies:\n","    fig = px.line(df, x=\"Date\", y=\"Close_diff\", \n","                  title=f\"Investigation of dates of anomalous changes in the first difference of the cryptocurrency rate\", \n","                  log_y=False,template='gridon',width=800, height=600)\n","    fig.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.002542Z","iopub.status.busy":"2022-06-08T12:57:11.002271Z","iopub.status.idle":"2022-06-08T12:57:11.007581Z","shell.execute_reply":"2022-06-08T12:57:11.006641Z","shell.execute_reply.started":"2022-06-08T12:57:11.00251Z"},"papermill":{"duration":0.287547,"end_time":"2022-05-24T12:31:25.583975","exception":false,"start_time":"2022-05-24T12:31:25.296428","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Add new anomalous dates\n","if is_anomalies:\n","    anomalous_dates_diff = anomalous_dates.copy()\n","    anomalous_dates_diff.append('2021-02-08')\n","    anomalous_dates_diff.append('2021-05-12')\n","    anomalous_dates_diff.append('2021-09-07')\n","    print(anomalous_dates_diff)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.009617Z","iopub.status.busy":"2022-06-08T12:57:11.008825Z","iopub.status.idle":"2022-06-08T12:57:11.038024Z","shell.execute_reply":"2022-06-08T12:57:11.037282Z","shell.execute_reply.started":"2022-06-08T12:57:11.009576Z"},"papermill":{"duration":0.30606,"end_time":"2022-05-24T12:31:26.16017","exception":false,"start_time":"2022-05-24T12:31:25.85411","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Synthesis dataframe with anomalous dates for Facebook Prophet\n","if is_anomalies:\n","    holidays_df_diff = pd.DataFrame(columns = ['ds', 'lower_window', 'upper_window', 'prior_scale'])\n","    holidays_df_diff['ds'] = anomalous_dates_diff\n","    holidays_df_diff['holiday'] = 'anomalous_dates_for_difference'\n","    holidays_df_diff['lower_window'] = 0\n","    holidays_df_diff['upper_window'] = 0\n","    holidays_df_diff['prior_scale'] = 10\n","    display(holidays_df_diff)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.039775Z","iopub.status.busy":"2022-06-08T12:57:11.039037Z","iopub.status.idle":"2022-06-08T12:57:11.129055Z","shell.execute_reply":"2022-06-08T12:57:11.128115Z","shell.execute_reply.started":"2022-06-08T12:57:11.039737Z"},"papermill":{"duration":0.394079,"end_time":"2022-05-24T12:31:26.824769","exception":false,"start_time":"2022-05-24T12:31:26.43069","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Draw plot\n","if is_anomalies:\n","    plot_with_anomalies(df, [\"Close_diff\"], \n","                        {\"Close_diff\" : f\"Anomalous dates for the first difference of the {cryptocurrency}\"}, \n","                        'Date', anomalous_dates_diff, False)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.131135Z","iopub.status.busy":"2022-06-08T12:57:11.130572Z","iopub.status.idle":"2022-06-08T12:57:11.171444Z","shell.execute_reply":"2022-06-08T12:57:11.170622Z","shell.execute_reply.started":"2022-06-08T12:57:11.131096Z"},"papermill":{"duration":0.293832,"end_time":"2022-05-24T12:31:27.385333","exception":false,"start_time":"2022-05-24T12:31:27.091501","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Synthesis a new feature in df for anomalous_dates_diff\n","if is_anomalies:\n","    df['Close_diff_anomalous'] = df['Date'].isin(anomalous_dates_diff).astype('int')    \n","    display(df)\n","    \n","    # Number of anomalous dates\n","    print(f\"Number of anomalous dates - {df['Close_diff_anomalous'].sum()}\")"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.2379,"end_time":"2022-05-24T12:31:28.522329","exception":false,"start_time":"2022-05-24T12:31:28.284429","status":"completed"},"tags":[]},"source":["### 4.4. Analysis of the impact of COVID-19 on the cryptocurrency rate <a class=\"anchor\" id=\"4.4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.173302Z","iopub.status.busy":"2022-06-08T12:57:11.172737Z","iopub.status.idle":"2022-06-08T12:57:11.178486Z","shell.execute_reply":"2022-06-08T12:57:11.177687Z","shell.execute_reply.started":"2022-06-08T12:57:11.173251Z"},"papermill":{"duration":0.26877,"end_time":"2022-05-24T12:31:29.035102","exception":false,"start_time":"2022-05-24T12:31:28.766332","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Set COVID parameters\n","if is_EDA_with_COVID19_data:\n","    covid_feature = 'New_Deaths'  # or \"New_Cases\"\n","    country_covid_feature = f\"USA_{covid_feature}\"\n","    print('country_covid_feature =', country_covid_feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.180182Z","iopub.status.busy":"2022-06-08T12:57:11.179948Z","iopub.status.idle":"2022-06-08T12:57:11.431529Z","shell.execute_reply":"2022-06-08T12:57:11.430376Z","shell.execute_reply.started":"2022-06-08T12:57:11.180153Z"},"papermill":{"duration":0.57552,"end_time":"2022-05-24T12:31:29.866557","exception":false,"start_time":"2022-05-24T12:31:29.291037","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_covid_data(date_start, covid_feature, country='USA'):\n","\n","    # Source: https://github.com/CSSEGISandData/COVID-19/tree/master/csse_covid_19_data/csse_covid_19_time_series\n","    \n","    if covid_feature=='New_Cases':\n","        file = \"time_series_covid19_confirmed_global.csv\"\n","        name_feature = 'Cases'\n","    elif covid_feature==\"New_Deaths\":\n","        file = \"time_series_covid19_deaths_global.csv\"\n","        name_feature = 'Deaths'\n","    \n","    myfile = requests.get(f'https://raw.githubusercontent.com/CSSEGISandData/COVID-19/master/csse_covid_19_data/csse_covid_19_time_series/{file}')\n","    open('data', 'wb').write(myfile.content)\n","    global_df = pd.read_csv('data')\n","    \n","    if country=='USA':\n","        code = 'US'\n","    else: code = country\n","    \n","    try:\n","        global_df = global_df[global_df['Country/Region']==code]\n","    except:\n","        print('Non-existent country code given')\n","        return None\n","\n","    def convert_date_str(df):\n","        try:\n","            df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n","        except:\n","            print('_convert_date_str failed with %y, try %Y')\n","            df.columns = list(df.columns[:4]) + [datetime.strptime(d, \"%m/%d/%Y\").date().strftime(\"%Y-%m-%d\") for d in df.columns[4:]]\n","\n","    convert_date_str(global_df)\n","    \n","    global_df2 = global_df.melt(\n","        id_vars=['Province/State', 'Country/Region', 'Lat', 'Long'], value_vars=global_df.columns[4:], var_name='Date', value_name=name_feature)\n","\n","    df_covid = global_df2[['Date', name_feature]]\n","    df_covid[name_feature] = df_covid[name_feature].astype('int').diff()\n","    df_covid = df_covid.fillna(0)\n","\n","    df_covid['ds'] = pd.to_datetime(df_covid['Date'])\n","    df_covid = df_covid[df_covid['ds'] > date_start][['ds', name_feature]].reset_index(drop=True)\n","    df_covid.columns = ['Date', country_covid_feature]\n","\n","    return df_covid\n","\n","if is_EDA_with_COVID19_data:\n","    df_covid = get_covid_data(date_start, covid_feature)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.433597Z","iopub.status.busy":"2022-06-08T12:57:11.433328Z","iopub.status.idle":"2022-06-08T12:57:11.474132Z","shell.execute_reply":"2022-06-08T12:57:11.473209Z","shell.execute_reply.started":"2022-06-08T12:57:11.433565Z"},"papermill":{"duration":0.361307,"end_time":"2022-05-24T12:31:30.523302","exception":false,"start_time":"2022-05-24T12:31:30.161995","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def df_covid_data_imputing(df_covid):\n","    # Imputing COVID data for USA\n","\n","    def pd_imputing(df, date1, date2, col):\n","        x1 = float(df[df['Date']==date1][col].head(1))\n","        x2 = float(df[df['Date']==date2][col].head(1))\n","        return (x1+x2)/2\n","\n","    def df_add(df, date_middle, date1, date2, col=country_covid_feature):\n","        # Add imputed COVID data for USA\n","        df = df.append({'Date': datetime.strptime(date_middle, '%Y-%m-%d'), col : pd_imputing(df, date1, date2, col=col)}, ignore_index=True)\n","        return df\n","\n","    # Only for USA - the imputing missing data\n","    date_anomal = ['2021-10-08', '2021-10-11', '2021-10-12', '2021-10-25']\n","    df_covid = df_add(df_covid, '2021-10-08', '2021-10-07', '2021-10-09')\n","    df_covid = df_add(df_covid, '2021-10-11', '2021-10-10', '2021-10-13')\n","    df_covid = df_add(df_covid, '2021-10-12', '2021-10-11', '2021-10-14')\n","    df_covid = df_add(df_covid, '2021-10-25', '2021-10-24', '2021-10-26')\n","    df_covid = df_covid.sort_values(by=['Date']).reset_index(drop=True)\n","    \n","    return df_covid\n","\n","if is_EDA_with_COVID19_data:\n","    df_covid = df_covid_data_imputing(df_covid)\n","    display(df_covid)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.476008Z","iopub.status.busy":"2022-06-08T12:57:11.475683Z","iopub.status.idle":"2022-06-08T12:57:11.500157Z","shell.execute_reply":"2022-06-08T12:57:11.499328Z","shell.execute_reply.started":"2022-06-08T12:57:11.475962Z"},"papermill":{"duration":0.386796,"end_time":"2022-05-24T12:31:31.235314","exception":false,"start_time":"2022-05-24T12:31:30.848518","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_EDA_with_COVID19_data:\n","    data = pd.merge(df[['Date', 'Close']], df_covid, on = 'Date')\n","    data.index = data['Date']\n","    display(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.501767Z","iopub.status.busy":"2022-06-08T12:57:11.501448Z","iopub.status.idle":"2022-06-08T12:57:11.811405Z","shell.execute_reply":"2022-06-08T12:57:11.810345Z","shell.execute_reply.started":"2022-06-08T12:57:11.501724Z"},"papermill":{"duration":0.725651,"end_time":"2022-05-24T12:31:32.285569","exception":false,"start_time":"2022-05-24T12:31:31.559918","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def draw_crypto_and_covid(data):\n","    # Displays COVID data in USA and cryptocurrency data on one plot\n","    \n","    def df_minmax_scaler(df):\n","        # Data Scalling\n","        index_df = df.pop('Date')\n","        scaler = MinMaxScaler().fit(df)\n","        df = pd.DataFrame(scaler.transform(df), columns = df.columns, index = index_df)\n","        return df\n","\n","    data = df_minmax_scaler(data.copy())\n","\n","    # Data smoothing and visualization\n","    cols_scaled = ['Close_Smoothed_Scaled', country_covid_feature + \"_Smoothed_Scaled\"]\n","    data.columns = cols_scaled\n","    for col in cols_scaled:\n","        data[col] = data[col].rolling(7).mean()\n","    data[cols_scaled].plot(lw=4, grid=True, figsize=(12,10))\n","\n","if is_EDA_with_COVID19_data:\n","    draw_crypto_and_covid(data)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.813349Z","iopub.status.busy":"2022-06-08T12:57:11.812999Z","iopub.status.idle":"2022-06-08T12:57:11.869768Z","shell.execute_reply":"2022-06-08T12:57:11.868704Z","shell.execute_reply.started":"2022-06-08T12:57:11.813285Z"},"papermill":{"duration":0.453353,"end_time":"2022-05-24T12:31:32.970153","exception":false,"start_time":"2022-05-24T12:31:32.5168","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Saving the dataset\n","if is_EDA_with_COVID19_data:\n","    df.to_csv(f'data_of_{cryptocurrency}.csv', index=False)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.324276,"end_time":"2022-05-24T12:31:33.672164","exception":false,"start_time":"2022-05-24T12:31:33.347888","status":"completed"},"tags":[]},"source":["### 4.5. Get target, training, validation and test datasets for ML models<a class=\"anchor\" id=\"4.5\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.873812Z","iopub.status.busy":"2022-06-08T12:57:11.873512Z","iopub.status.idle":"2022-06-08T12:57:11.916882Z","shell.execute_reply":"2022-06-08T12:57:11.916248Z","shell.execute_reply.started":"2022-06-08T12:57:11.873771Z"},"papermill":{"duration":0.274755,"end_time":"2022-05-24T12:31:34.186829","exception":false,"start_time":"2022-05-24T12:31:33.912074","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Illustration of number transformations in the columns:\n","# \"Close\" -> \"Close_diff\" -> \"Target\" -> \"Close_diff_pred\" -> \"Close_pred\"\n","# Get target and the result of the forecasting\n","forecasting_days_example = 3\n","df_example = pd.DataFrame({'Close':[1, 2, 4, 8, 15, 25], 'Day': [0, 1, 2, 3, 4, 5]})\n","df_example['Close_diff'] = df_example['Close'].diff()\n","df_example['target'] = df_example['Close_diff'].shift(-forecasting_days_example)\n","df_example['target_pred'] = df_example['target'].copy()   # Ideal forecasting result\n","print(f'Simulation of the result of ideal forecasting the \"target_pred\" for {forecasting_days_example} days')\n","display(df_example[['Day', 'Close', 'Close_diff', 'target', 'target_pred']])\n","\n","# Get inverse target\n","print('\\nSimulation of the recovering predicted values \"Close_pred\" from the \"target_pred\"')\n","df_example['Close_diff_pred_shifted'] = df_example['target_pred'].shift(forecasting_days_example)\n","\n","# Let's create an intermediate feature to make it easier to explain the transformation\n","temp_column_name = f'Close_diff_pred_shifted_with_Close'  # Intermediate feature for transformations \n","df_example[temp_column_name] = df_example['Close_diff_pred_shifted'].copy()\n","df_example.loc[forecasting_days_example, temp_column_name] = df_example.loc[forecasting_days_example,'Close']\n","df_example['Close_pred'] = np.concatenate((df_example['Close'].tolist()[:forecasting_days_example], \n","                                           np.cumsum(df_example[temp_column_name].values[forecasting_days_example:], dtype=float)))\n","df_example['Close_pred'] = df_example['Close_pred'].astype('int')\n","display(df_example[['Day', 'Close', 'Close_diff', 'target', 'target_pred', 'Close_diff_pred_shifted', temp_column_name, 'Close_pred']])"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.225172,"end_time":"2022-05-24T12:31:34.635699","exception":false,"start_time":"2022-05-24T12:31:34.410527","status":"completed"},"tags":[]},"source":["1. Recovery is possible if you know exactly at least one value \"Close\".\n","2. If the last N values for the time series will be in the target_test, then during the comparing with the output of other multi-features ML models needs remember that in them the target is shifted back and taken with a difference.\n","3. Target for Time series model is \"Close\". \n","4. Target is for multi-factors models is \"target_pred\" = shifted \"Close_diff\"."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.918492Z","iopub.status.busy":"2022-06-08T12:57:11.917889Z","iopub.status.idle":"2022-06-08T12:57:11.923021Z","shell.execute_reply":"2022-06-08T12:57:11.922405Z","shell.execute_reply.started":"2022-06-08T12:57:11.918457Z"},"papermill":{"duration":0.240302,"end_time":"2022-05-24T12:31:35.10219","exception":false,"start_time":"2022-05-24T12:31:34.861888","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def cut_data(df, y, num_start, num_end):\n","    # Cutting dataframe df and array or list for [num_start, num_end-1]        \n","    df2 = df[num_start:(num_end+1)]\n","    y2 = y[num_start:(num_end+1)] if y is not None else None\n","    return df2, y2"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.924731Z","iopub.status.busy":"2022-06-08T12:57:11.924211Z","iopub.status.idle":"2022-06-08T12:57:11.936757Z","shell.execute_reply":"2022-06-08T12:57:11.935604Z","shell.execute_reply.started":"2022-06-08T12:57:11.924686Z"},"papermill":{"duration":0.232925,"end_time":"2022-05-24T12:31:35.559008","exception":false,"start_time":"2022-05-24T12:31:35.326083","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_target_mf(df, forecasting_days, col='Close'):\n","    # Get target as difference of the df[col] \n","    # Returns target which is shifted for forecasting_days days in the dataframe df\n","    # \"Close\" -> \"Close_diff\" -> \"Target\" \n","    col_diff = f\"{col}_diff\"\n","    df[col_diff] = df['Close'].diff()\n","    df['target'] = df[col_diff].shift(-forecasting_days)\n","    df = df.drop(columns=[col_diff]).dropna()\n","    \n","    return df"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.938668Z","iopub.status.busy":"2022-06-08T12:57:11.93841Z","iopub.status.idle":"2022-06-08T12:57:11.953854Z","shell.execute_reply":"2022-06-08T12:57:11.952742Z","shell.execute_reply.started":"2022-06-08T12:57:11.938635Z"},"papermill":{"duration":0.238826,"end_time":"2022-05-24T12:31:36.022024","exception":false,"start_time":"2022-05-24T12:31:35.783198","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_train_valid_test_ts(df, forecasting_days, target='Close'):\n","    # Get training, validation and test datasets with target for Time Series models\n","    \n","    # Data prepairing\n","    df = df.dropna(how=\"any\").reset_index(drop=True)\n","    df = df[['Date', 'Close']]\n","    df.columns = ['ds', 'y']        \n","    y = None\n","\n","    # Data smoothing\n","#     df.index = df.ds\n","#     df = df.drop(columns=['ds'])\n","#     df['y'] = df['y'].rolling(7).mean()\n","#     df = df.dropna().reset_index(drop=False)\n","    \n","    N = len(df)\n","    train, _ = cut_data(df, y, 0, N-2*forecasting_days-1)\n","    valid, _ = cut_data(df, y, N-2*forecasting_days, N-forecasting_days-1)\n","    test, _ = cut_data(df, y, N-forecasting_days, N)\n","    \n","    # Train+valid - for optimal model training\n","    train_valid = pd.concat([train, valid])\n","\n","    print(f'Origin dataset has {len(df)} rows and {len(df.columns)} features')\n","    print(f'Get training dataset with {len(train)} rows')\n","    print(f'Get validation dataset with {len(valid)} rows')\n","    print(f'Get test dataset with {len(test)} rows')\n","    \n","    return train, valid, test, train_valid"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.955368Z","iopub.status.busy":"2022-06-08T12:57:11.955099Z","iopub.status.idle":"2022-06-08T12:57:11.96717Z","shell.execute_reply":"2022-06-08T12:57:11.966221Z","shell.execute_reply.started":"2022-06-08T12:57:11.955332Z"},"papermill":{"duration":0.236836,"end_time":"2022-05-24T12:31:36.486823","exception":false,"start_time":"2022-05-24T12:31:36.249987","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_train_valid_test_mf(df, forecasting_days, target='target'):\n","    # Get training, validation and test datasets with target for multi-features ML models\n","    \n","    df = df.drop(columns = ['Date']).dropna(how=\"any\").reset_index(drop=True)\n","    \n","    # Save and drop target        \n","    y = df.pop(target)\n","\n","    # Get starting points for the recovering \"Close\" from \"Close_diff_shigted\"\n","    N = len(df)\n","    #print(f\"Total - {N}, Valid start index = {N-forecasting_days-1}, Test start index = {N-1}\")\n","    start_points = {'valid_start_point' : df.loc[N-forecasting_days-1, 'Close'],\n","                    'test_start_point' : df.loc[N-1, 'Close']}\n","\n","    # Standartization data\n","    scaler = StandardScaler()\n","    df = pd.DataFrame(scaler.fit_transform(df), columns = df.columns)\n","    \n","    \n","    train, ytrain = cut_data(df.copy(), y, 0, N-2*forecasting_days-1)\n","    valid, yvalid = cut_data(df.copy(), y, N-2*forecasting_days, N-forecasting_days-1)\n","    test, ytest = cut_data(df.copy(), y, N-forecasting_days, N)\n","\n","\n","    # Train+valid - for optimal model training\n","    train_valid = pd.concat([train, valid])\n","    y_train_valid = pd.concat([ytrain, yvalid])\n","\n","    print(f'Origin dataset has {len(df)} rows and {len(df.columns)} features')\n","    print(f'Get training dataset with {len(train)} rows')\n","    print(f'Get validation dataset with {len(valid)} rows')\n","    print(f'Get test dataset with {len(test)} rows')\n","    \n","    return train, ytrain, valid, yvalid, test, ytest, train_valid, y_train_valid, start_points"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.223015,"end_time":"2022-05-24T12:31:36.934315","exception":false,"start_time":"2022-05-24T12:31:36.7113","status":"completed"},"tags":[]},"source":["## 5. Model training and forecasting <a class=\"anchor\" id=\"5\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.220381,"end_time":"2022-05-24T12:31:37.37977","exception":false,"start_time":"2022-05-24T12:31:37.159389","status":"completed"},"tags":[]},"source":["This section provides examples of identifying the following models (but the list goes on):\n","* Facebook Prophet \n","* ARIMA (and AutoARIMA)\n","* Linear Regression\n","* KNeighbors Regressor\n","* Support Vector Machines\n","* Linear SVR\n","* Random Forest Regressor\n","* Bagging Regressor\n","* XGB Regressor\n","* MLP Regressor\n","\n","FB Prophet and ARIMA models have a slightly different data format, while other Machine Learning (ML) models have the same data, so it is easy to increase their number.\n","\n","Classic model XGBoost have a special format, but this notebook  uses its simplified version, which work in a data format similar to the models of the Sklearn library.\n","\n","Models based on neural networks (based on PyTorch or Keras) and ensembles of all these models are more effective, but this will be done later in other notebooks."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.969188Z","iopub.status.busy":"2022-06-08T12:57:11.968848Z","iopub.status.idle":"2022-06-08T12:57:11.98526Z","shell.execute_reply":"2022-06-08T12:57:11.984491Z","shell.execute_reply.started":"2022-06-08T12:57:11.969146Z"},"papermill":{"duration":0.239411,"end_time":"2022-05-24T12:31:37.842492","exception":false,"start_time":"2022-05-24T12:31:37.603081","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def calc_metrics(type_score, list_true, list_pred):\n","    # Calculation score with type=type_score for list_true and list_pred \n","    if type_score=='r2_score':\n","        score = r2_score(list_true, list_pred)\n","    elif type_score=='rmse':\n","        score = mean_squared_error(list_true, list_pred, squared=False)\n","    elif type_score=='mape':\n","        score = mean_absolute_percentage_error(list_true, list_pred)\n","    return score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.988606Z","iopub.status.busy":"2022-06-08T12:57:11.987568Z","iopub.status.idle":"2022-06-08T12:57:11.997172Z","shell.execute_reply":"2022-06-08T12:57:11.996375Z","shell.execute_reply.started":"2022-06-08T12:57:11.988555Z"},"papermill":{"duration":0.233029,"end_time":"2022-05-24T12:31:38.30027","exception":false,"start_time":"2022-05-24T12:31:38.067241","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def result_add_metrics(result, n, y_true, y_pred):\n","    # Calculation and addition metrics into dataframe result[n,:]\n","    \n","    result.loc[n,'r2_score'] = calc_metrics('r2_score', y_true, y_pred)\n","    result.loc[n,'rmse'] = calc_metrics('rmse', y_true, y_pred)      # in coins\n","    result.loc[n,'mape'] = 100*calc_metrics('mape', y_true, y_pred)  # in %\n","    \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:11.998815Z","iopub.status.busy":"2022-06-08T12:57:11.998437Z","iopub.status.idle":"2022-06-08T12:57:12.018679Z","shell.execute_reply":"2022-06-08T12:57:12.017771Z","shell.execute_reply.started":"2022-06-08T12:57:11.998775Z"},"papermill":{"duration":0.247194,"end_time":"2022-05-24T12:31:38.765253","exception":false,"start_time":"2022-05-24T12:31:38.518059","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Results of all models\n","result = pd.DataFrame(columns = ['name_model', 'type_data', 'r2_score', 'rmse', 'mape', 'params', 'ypred'])"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.226077,"end_time":"2022-05-24T12:31:39.248195","exception":false,"start_time":"2022-05-24T12:31:39.022118","status":"completed"},"tags":[]},"source":["### 5.1.Prophet <a class=\"anchor\" id=\"5.1\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:12.020309Z","iopub.status.busy":"2022-06-08T12:57:12.02002Z","iopub.status.idle":"2022-06-08T12:57:12.065898Z","shell.execute_reply":"2022-06-08T12:57:12.064986Z","shell.execute_reply.started":"2022-06-08T12:57:12.020262Z"},"papermill":{"duration":0.262975,"end_time":"2022-05-24T12:31:40.185019","exception":false,"start_time":"2022-05-24T12:31:39.922044","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Modeling 2022 year only\n","if is_Prophet:\n","    df2 = df[df.Date.dt.year == 2022]\n","    display(df2)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:12.068227Z","iopub.status.busy":"2022-06-08T12:57:12.067312Z","iopub.status.idle":"2022-06-08T12:57:12.080503Z","shell.execute_reply":"2022-06-08T12:57:12.079812Z","shell.execute_reply.started":"2022-06-08T12:57:12.068177Z"},"papermill":{"duration":0.23801,"end_time":"2022-05-24T12:31:40.648268","exception":false,"start_time":"2022-05-24T12:31:40.410258","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get datasets\n","if is_Prophet:\n","    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df2.copy(), forecasting_days, target='Close')\n","    \n","    if not is_anomalies:\n","        holidays_df = None"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:12.08248Z","iopub.status.busy":"2022-06-08T12:57:12.082057Z","iopub.status.idle":"2022-06-08T12:57:12.093201Z","shell.execute_reply":"2022-06-08T12:57:12.092487Z","shell.execute_reply.started":"2022-06-08T12:57:12.082444Z"},"papermill":{"duration":0.244085,"end_time":"2022-05-24T12:31:41.116764","exception":false,"start_time":"2022-05-24T12:31:40.872679","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def prophet_modeling(result, \n","                     cryptocurrency, \n","                     train, \n","                     test, \n","                     holidays_df, \n","                     period_days,\n","                     fourier_order_seasonality,\n","                     forecasting_period,\n","                     name_model,\n","                     type_data):\n","    # Performs FB Prophet model training for given train dataset, holidays_df and seasonality_mode\n","    # Performs forecasting with period by this model, visualization and error estimation\n","    # df - dataframe with real data in the forecasting_period\n","    # can be such combinations of parameters: train=train, test=valid or train=train_valid, test=test\n","    # Save results into dataframe result\n","    \n","    # Build Prophet model with parameters and structure \n","    model = Prophet(daily_seasonality=False, \n","                    weekly_seasonality=False, \n","                    yearly_seasonality=False, \n","                    changepoint_range=1, \n","                    changepoint_prior_scale = 0.5, \n","                    holidays=holidays_df, \n","                    seasonality_mode = 'multiplicative'\n","                   )\n","    model.add_seasonality(name='seasonality', period=period_days, \n","                          fourier_order=fourier_order_seasonality, \n","                          mode = 'multiplicative', prior_scale = 0.5)\n","    # Training model for df\n","    model.fit(train)\n","    \n","    # Make a forecast\n","    future = model.make_future_dataframe(periods = forecasting_period)\n","    forecast = model.predict(future)\n","    \n","    # Draw plot of the values with forecasting data\n","    figure = model.plot(forecast, xlabel = 'Date', ylabel = f\"{name_model} for {cryptocurrency}\")\n","    \n","    # Draw plot with the components (trend and seasonalities) of the forecasts\n","    figure_component = model.plot_components(forecast)\n","    \n","    # Ouput the prediction for the next time on forecasted_days\n","    #forecast[['yhat_lower', 'yhat', 'yhat_upper']] = forecast[['yhat_lower', 'yhat', 'yhat_upper']].round(1)\n","    #forecast[['ds', 'yhat_lower', 'yhat', 'yhat_upper']].tail(forecasting_period)\n","    \n","    # Forecasting data by the model\n","    ypred = forecast['yhat'][-forecasting_period:]\n","    #print(ypred)\n","    # Save results\n","    n = len(result)\n","    result.loc[n,'name_model'] = f\"Prophet_{name_model}\"\n","    result.loc[n,'type_data'] = type_data\n","    result.at[n,'params'] = [period_days]+[fourier_order_seasonality]\n","    result.at[n,'ypred'] = ypred\n","    #result = result_add_metrics(result, n, test['y'], y_pred)\n","    \n","    return result, ypred"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.227138,"end_time":"2022-05-24T12:31:41.568735","exception":false,"start_time":"2022-05-24T12:31:41.341597","status":"completed"},"tags":[]},"source":["**TASK :** It is proposed to experiment with models parameters"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:12.094895Z","iopub.status.busy":"2022-06-08T12:57:12.094501Z","iopub.status.idle":"2022-06-08T12:57:41.572526Z","shell.execute_reply":"2022-06-08T12:57:41.571577Z","shell.execute_reply.started":"2022-06-08T12:57:12.094855Z"},"papermill":{"duration":32.424702,"end_time":"2022-05-24T12:32:14.225596","exception":false,"start_time":"2022-05-24T12:31:41.800894","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%time\n","# Models tuning\n","if is_Prophet:\n","    for period_days in [4, 5, 7, 14]:\n","        for fourier_order_seasonality in [3, 12]:\n","            result, _ = prophet_modeling(result, \n","                                         cryptocurrency, \n","                                         train_ts, \n","                                         valid_ts, \n","                                         holidays_df, \n","                                         period_days,\n","                                         fourier_order_seasonality,\n","                                         forecasting_days,\n","                                         f'{period_days}_days_{fourier_order_seasonality}_order',\n","                                         'valid')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.28108,"end_time":"2022-05-24T12:32:14.787502","exception":false,"start_time":"2022-05-24T12:32:14.506422","status":"completed"},"tags":[]},"source":["### 5.2. ARIMA <a class=\"anchor\" id=\"5.2\"></a>\n","\n","This information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n","\n","ARIMA stands for Autoregressive Integrated Moving Average Model. It belongs to a class of models that explains a given time series based on its own past values -i.e.- its own lags and the lagged forecast errors. The equation can be used to forecast future values. Any non-seasonal time series that exhibits patterns and is not a random white noise can be modeled with ARIMA models.\n","So, ARIMA, short for AutoRegressive Integrated Moving Average, is a forecasting algorithm based on the idea that the information in the past values of the time series can alone be used to predict the future values.\n","ARIMA Models are specified by three order parameters: (p, d, q),\n","\n","where,\n","\n","- p is the order of the AR term\n","\n","- d is the number of differencing required to make the time series stationary\n","\n","- q is the order of the MA term\n","\n","\n","- AR(p) Autoregression  a regression model that utilizes the dependent relationship between a current observation and observations over a previous period. An auto regressive (AR(p)) component refers to the use of past values in the regression equation for the time series.\n","\n","- I(d) Integration  uses differencing of observations (subtracting an observation from observation at the previous time step) in order to make the time series stationary. Differencing involves the subtraction of the current values of a series with its previous values d number of times.\n","\n","- MA(q) Moving Average  a model that uses the dependency between an observation and a residual error from a moving average model applied to lagged observations. A moving average component depicts the error of the model as a combination of previous error terms. The order q represents the number of terms to be included in the model."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:41.574259Z","iopub.status.busy":"2022-06-08T12:57:41.574001Z","iopub.status.idle":"2022-06-08T12:57:41.586253Z","shell.execute_reply":"2022-06-08T12:57:41.585298Z","shell.execute_reply.started":"2022-06-08T12:57:41.574228Z"},"papermill":{"duration":0.299199,"end_time":"2022-05-24T12:32:15.367466","exception":false,"start_time":"2022-05-24T12:32:15.068267","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get datasets\n","if is_ARIMA:\n","    train_ts, valid_ts, test_ts, train_valid_ts = get_train_valid_test_ts(df2.copy(), forecasting_days, target='Close')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.282202,"end_time":"2022-05-24T12:32:15.932551","exception":false,"start_time":"2022-05-24T12:32:15.650349","status":"completed"},"tags":[]},"source":["#### **5.2.1 How to find the order of differencing (d) in ARIMA model**  <a class=\"anchor\" id=\"5.2.1\"></a>\n","\n","This information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n","\n","- As stated earlier, the purpose of differencing is to make the time series stationary. But we should be careful to not over-difference the series. An over differenced series may still be stationary, which in turn will affect the model parameters.\n","\n","\n","- So we should determine the right order of differencing. The right order of differencing is the minimum differencing required to get a near-stationary series which roams around a defined mean and the ACF plot reaches to zero fairly quick.\n","\n","\n","- If the autocorrelations are positive for many number of lags (10 or more), then the series needs further differencing. On the other hand, if the lag 1 autocorrelation itself is too negative, then the series is probably over-differenced.\n","\n","\n","- If we cant really decide between two orders of differencing, then we go with the order that gives the least standard deviation in the differenced series.\n","\n","\n","- Now, we will explain these concepts with the help of an example as follows:\n","\n","\n","- First, I will check if the series is stationary using the **Augmented Dickey Fuller test (ADF Test)**, from the statsmodels package. The reason being is that we need differencing only if the series is non-stationary. Else, no differencing is needed, that is, d=0.\n","\n","\n","- The null hypothesis (Ho) of the ADF test is that the time series is non-stationary. So, if the p-value of the test is less than the significance level (0.05) then we reject the null hypothesis and infer that the time series is indeed stationary.\n","\n","\n","- So, in our case, if P Value > 0.05 we go ahead with finding the order of differencing.\n","\n","- **A similar analysis has already been made in the paragraph \"3.4. Stationarity check\" above**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:41.588485Z","iopub.status.busy":"2022-06-08T12:57:41.587575Z","iopub.status.idle":"2022-06-08T12:57:41.60075Z","shell.execute_reply":"2022-06-08T12:57:41.599394Z","shell.execute_reply.started":"2022-06-08T12:57:41.588427Z"},"papermill":{"duration":0.299802,"end_time":"2022-05-24T12:32:16.513728","exception":false,"start_time":"2022-05-24T12:32:16.213926","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def acf_pacf_draw(df, lag_num=40, acf=True, pacf=True, title=\"\", ylim=1):\n","    # Draw plots named title with ACF and PACF for dataframe df\n","    \n","    num_plots = 1+int(acf)+int(pacf)\n","    fig, ax = plt.subplots(1,num_plots,figsize=(12,6))\n","    # 'Original Series'\n","    ax[0].plot(df.values.squeeze())\n","    \n","    if acf:\n","        # ACF drawing\n","        plot_acf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n","        ax[1].set(ylim=(-ylim, ylim))\n","        \n","        if pacf:\n","            # PACF drawing\n","            plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[2])\n","            ax[2].set(ylim=(-ylim, ylim))\n","        \n","    elif pacf:\n","        # PACF drawing\n","        plot_pacf(df.values.squeeze(), lags=lag_num, ax=ax[1])\n","        ax[1].set(ylim=(-ylim, ylim))\n","\n","    fig.suptitle(title)\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:41.602463Z","iopub.status.busy":"2022-06-08T12:57:41.602131Z","iopub.status.idle":"2022-06-08T12:57:43.198479Z","shell.execute_reply":"2022-06-08T12:57:43.197522Z","shell.execute_reply.started":"2022-06-08T12:57:41.602425Z"},"papermill":{"duration":2.108014,"end_time":"2022-05-24T12:32:18.898179","exception":false,"start_time":"2022-05-24T12:32:16.790165","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # ACF and PACF\n","    lag_num = 100\n","    acf_pacf_draw(train_ts['y'], lag_num, True, True, 'Original Series')\n","    acf_pacf_draw(train_ts['y'].diff().dropna(), lag_num, True, True, '1st Order Differencing')\n","    acf_pacf_draw(train_ts['y'].diff().diff().dropna(), lag_num, True, True, '2nd Order Differencing')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.28468,"end_time":"2022-05-24T12:32:19.472286","exception":false,"start_time":"2022-05-24T12:32:19.187606","status":"completed"},"tags":[]},"source":["- For the above data, we can see that the time series reaches stationarity with first orders of differencing. Although, it value may be higher, as can be seen from the larger values of the lag."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.199903Z","iopub.status.busy":"2022-06-08T12:57:43.199683Z","iopub.status.idle":"2022-06-08T12:57:43.204343Z","shell.execute_reply":"2022-06-08T12:57:43.203327Z","shell.execute_reply.started":"2022-06-08T12:57:43.199876Z"},"papermill":{"duration":0.296759,"end_time":"2022-05-24T12:32:20.060415","exception":false,"start_time":"2022-05-24T12:32:19.763656","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["d = 1"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.287412,"end_time":"2022-05-24T12:32:20.637435","exception":false,"start_time":"2022-05-24T12:32:20.350023","status":"completed"},"tags":[]},"source":["#### **5.2.2. How to find the order of the AR term (p)** <a class=\"anchor\" id=\"5.2.2\"></a>\n","\n","[Table of Contents](#0.1)\n","\n","This information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n","\n","- The next step is to identify if the model needs any AR terms. We will find out the required number of AR terms by inspecting the **Partial Autocorrelation (PACF) plot**.\n","\n","\n","- **Partial autocorrelation** can be imagined as the correlation between the series and its lag, after excluding the contributions from the intermediate lags. So, PACF sort of conveys the pure correlation between a lag and the series. This way, we will know if that lag is needed in the AR term or not.\n","\n","\n","- Partial autocorrelation of lag (k) of a series is the coefficient of that lag in the autoregression equation of Y.\n","\n","\n","$$Yt = \\alpha0 + \\alpha1 Y{t-1} + \\alpha2 Y{t-2} + \\alpha3 Y{t-3}$$\n","\n","\n","- That is, suppose, if Y_t is the current series and Y_t-1 is the lag 1 of Y, then the partial autocorrelation of lag 3 (Y_t-3) is the coefficient $\\alpha_3$ of Y_t-3 in the above equation.\n","\n","\n","- Now, we should find the number of AR terms. Any autocorrelation in a stationarized series can be rectified by adding enough AR terms. So, we initially take the order of AR term to be equal to as many lags that crosses the significance limit in the PACF plot.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.206341Z","iopub.status.busy":"2022-06-08T12:57:43.205783Z","iopub.status.idle":"2022-06-08T12:57:43.554318Z","shell.execute_reply":"2022-06-08T12:57:43.553319Z","shell.execute_reply.started":"2022-06-08T12:57:43.206186Z"},"papermill":{"duration":0.656261,"end_time":"2022-05-24T12:32:21.582245","exception":false,"start_time":"2022-05-24T12:32:20.925984","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# PACF drawing\n","if is_ARIMA:\n","    acf_pacf_draw(train_ts['y'].diff().dropna(), 30, False, True, '1st Order Differencing', 1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.293191,"end_time":"2022-05-24T12:32:22.170241","exception":false,"start_time":"2022-05-24T12:32:21.87705","status":"completed"},"tags":[]},"source":["- We can see that the PACF lag 0 is quite significant since it is well above the significance line. So, we will fix the value of p as 1. Although, it value may be higher, as can be seen from the larger values of the lag."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.556265Z","iopub.status.busy":"2022-06-08T12:57:43.555931Z","iopub.status.idle":"2022-06-08T12:57:43.561045Z","shell.execute_reply":"2022-06-08T12:57:43.559987Z","shell.execute_reply.started":"2022-06-08T12:57:43.556221Z"},"papermill":{"duration":0.305834,"end_time":"2022-05-24T12:32:22.76565","exception":false,"start_time":"2022-05-24T12:32:22.459816","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["p = 0"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.290701,"end_time":"2022-05-24T12:32:23.379056","exception":false,"start_time":"2022-05-24T12:32:23.088355","status":"completed"},"tags":[]},"source":["#### **5.2.3. How to find the order of the MA term (q)** <a class=\"anchor\" id=\"5.2.3\"></a>\n","\n","This information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n","\n","- Just like how we looked at the PACF plot for the number of AR terms, we will look at the ACF plot for the number of MA terms. An MA term is technically, the error of the lagged forecast.\n","\n","\n","- The ACF tells how many MA terms are required to remove any autocorrelation in the stationarized series.\n","\n","\n","- Lets see the autocorrelation plot of the differenced series."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.562829Z","iopub.status.busy":"2022-06-08T12:57:43.562581Z","iopub.status.idle":"2022-06-08T12:57:43.899414Z","shell.execute_reply":"2022-06-08T12:57:43.898371Z","shell.execute_reply.started":"2022-06-08T12:57:43.562797Z"},"papermill":{"duration":0.663101,"end_time":"2022-05-24T12:32:24.332354","exception":false,"start_time":"2022-05-24T12:32:23.669253","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# ACF drawing\n","if is_ARIMA:\n","    acf_pacf_draw(train_ts['y'].diff().dropna(), 30, True, False, '1st Order Differencing', 1)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.296778,"end_time":"2022-05-24T12:32:24.916535","exception":false,"start_time":"2022-05-24T12:32:24.619757","status":"completed"},"tags":[]},"source":["- We can see that couple of lags are well above the significance line. So, we will fix q as 0. If there is any doubt, we will go with the simpler model that sufficiently explains the Y."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.901254Z","iopub.status.busy":"2022-06-08T12:57:43.900935Z","iopub.status.idle":"2022-06-08T12:57:43.905471Z","shell.execute_reply":"2022-06-08T12:57:43.904748Z","shell.execute_reply.started":"2022-06-08T12:57:43.901211Z"},"papermill":{"duration":0.298407,"end_time":"2022-05-24T12:32:25.507715","exception":false,"start_time":"2022-05-24T12:32:25.209308","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["q = 0"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.294081,"end_time":"2022-05-24T12:32:26.092846","exception":false,"start_time":"2022-05-24T12:32:25.798765","status":"completed"},"tags":[]},"source":["#### **5.2.4. How to build the ARIMA Model with manually defined parameters** <a class=\"anchor\" id=\"5.2.4\"></a>\n","\n","\n","Now, we have determined the values of p, d and q. We have everything needed to fit the ARIMA model. We will use the ARIMA() implementation in the statsmodels package."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.907096Z","iopub.status.busy":"2022-06-08T12:57:43.906837Z","iopub.status.idle":"2022-06-08T12:57:43.918779Z","shell.execute_reply":"2022-06-08T12:57:43.917806Z","shell.execute_reply.started":"2022-06-08T12:57:43.907067Z"},"papermill":{"duration":0.300228,"end_time":"2022-05-24T12:32:26.683959","exception":false,"start_time":"2022-05-24T12:32:26.383731","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def arima_fit(df, col, order=(1,1,1)):\n","    # ARIMA model fitting for series df[col]\n","    \n","    model = sm.tsa.arima.ARIMA(df[col].values.squeeze(), order=order)\n","    model = model.fit()\n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.920527Z","iopub.status.busy":"2022-06-08T12:57:43.919899Z","iopub.status.idle":"2022-06-08T12:57:43.956397Z","shell.execute_reply":"2022-06-08T12:57:43.955742Z","shell.execute_reply.started":"2022-06-08T12:57:43.920494Z"},"papermill":{"duration":0.370275,"end_time":"2022-05-24T12:32:27.347847","exception":false,"start_time":"2022-05-24T12:32:26.977572","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # ARIMA Model tuning\n","    model = arima_fit(train_ts, 'y', order=(p,d,q))\n","    print(model.summary())"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.293218,"end_time":"2022-05-24T12:32:27.934352","exception":false,"start_time":"2022-05-24T12:32:27.641134","status":"completed"},"tags":[]},"source":["- The model summary provides lot of information. The table in the middle is the coefficients table where the values under coef are the weights of the respective terms.\n","\n","- The model AIC has slightly reduced, which is good. The p-values  in P>|z| column is highly significant (<< 0.05)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:43.957824Z","iopub.status.busy":"2022-06-08T12:57:43.957493Z","iopub.status.idle":"2022-06-08T12:57:44.611867Z","shell.execute_reply":"2022-06-08T12:57:44.611022Z","shell.execute_reply.started":"2022-06-08T12:57:43.957796Z"},"papermill":{"duration":0.996774,"end_time":"2022-05-24T12:32:29.235997","exception":false,"start_time":"2022-05-24T12:32:28.239223","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # ARIMA model diagnostics\n","    fig = model.plot_diagnostics(figsize=(12,10))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.29215,"end_time":"2022-05-24T12:32:29.822344","exception":false,"start_time":"2022-05-24T12:32:29.530194","status":"completed"},"tags":[]},"source":["#### **Interpretation of plots in plot diagnostics**\n","\n","This information from the good notebook [ARIMA Model for Time Series Forecasting](https://www.kaggle.com/code/prashant111/arima-model-for-time-series-forecasting)\n","\n","**Standardized residual**: The residual errors seem to fluctuate around a mean of zero and have a uniform variance.\n","\n","\n","**Histogram**: The density plot suggest normal distribution with mean slighlty shifted towards right.\n","\n","\n","**Theoretical Quantiles**: Mostly the dots fall perfectly in line with the red line. Any significant deviations would imply the distribution is skewed.\n","\n","\n","**Correlogram**: The Correlogram, (or ACF plot) shows the residual errors are not autocorrelated. The ACF plot would imply that there is some pattern in the residual errors which are not explained in the model. So we will need to look for more Xs (predictors) to the model.\n","\n","\n","Overall, the model seems to be a good fit. Lets plot the residuals to ensure there are no patterns (that is, look for constant mean and variance)."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:44.613622Z","iopub.status.busy":"2022-06-08T12:57:44.613385Z","iopub.status.idle":"2022-06-08T12:57:44.62127Z","shell.execute_reply":"2022-06-08T12:57:44.620138Z","shell.execute_reply.started":"2022-06-08T12:57:44.613592Z"},"papermill":{"duration":0.302024,"end_time":"2022-05-24T12:32:30.433366","exception":false,"start_time":"2022-05-24T12:32:30.131342","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_residual_errors(model):\n","    # Calculation and drawing the plot residual errors for ARIMA model\n","    residuals = pd.DataFrame(model.resid)\n","    fig, ax = plt.subplots(1,2, figsize=(12,6))\n","    residuals.plot(title=\"Residuals\", ax=ax[0])\n","    residuals.plot(kind='kde', title='Density', ax=ax[1])\n","    plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:44.623031Z","iopub.status.busy":"2022-06-08T12:57:44.622699Z","iopub.status.idle":"2022-06-08T12:57:44.975808Z","shell.execute_reply":"2022-06-08T12:57:44.974886Z","shell.execute_reply.started":"2022-06-08T12:57:44.622988Z"},"papermill":{"duration":0.6682,"end_time":"2022-05-24T12:32:31.397777","exception":false,"start_time":"2022-05-24T12:32:30.729577","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # Plot residual errors\n","    get_residual_errors(model)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.297561,"end_time":"2022-05-24T12:32:31.994239","exception":false,"start_time":"2022-05-24T12:32:31.696678","status":"completed"},"tags":[]},"source":["- The residual errors seem fine with near zero mean and uniform variance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:44.978043Z","iopub.status.busy":"2022-06-08T12:57:44.977499Z","iopub.status.idle":"2022-06-08T12:57:44.985466Z","shell.execute_reply":"2022-06-08T12:57:44.984323Z","shell.execute_reply.started":"2022-06-08T12:57:44.97799Z"},"papermill":{"duration":0.307088,"end_time":"2022-05-24T12:32:32.600402","exception":false,"start_time":"2022-05-24T12:32:32.293314","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def arima_forecasting(result, model, params, name_model, df, type_data):\n","    # Data df (validation or test) forecasting on the num days by the model \n","    # with params and save metrics to result \n","    \n","    ypred = model.forecast(steps=len(df))\n","    \n","    n = len(result)\n","    result.loc[n,'name_model'] = name_model\n","    result.loc[n,'type_data'] = type_data\n","    result.at[n,'params'] = params\n","    result.at[n,'ypred'] = ypred\n","    #result = result_add_metrics(result, n, df['y'], y_pred)\n","    \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:44.987496Z","iopub.status.busy":"2022-06-08T12:57:44.987067Z","iopub.status.idle":"2022-06-08T12:57:45.003456Z","shell.execute_reply":"2022-06-08T12:57:45.00248Z","shell.execute_reply.started":"2022-06-08T12:57:44.98745Z"},"papermill":{"duration":0.314995,"end_time":"2022-05-24T12:32:33.22003","exception":false,"start_time":"2022-05-24T12:32:32.905035","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # Valid forecasting and save result\n","    result = arima_forecasting(result, model, [p]+[d]+[q], 'ARIMA_manual', valid_ts, 'valid')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.319348,"end_time":"2022-05-24T12:32:33.83988","exception":false,"start_time":"2022-05-24T12:32:33.520532","status":"completed"},"tags":[]},"source":["#### **5.2.5. How to build the ARIMA automatically** <a class=\"anchor\" id=\"5.2.5\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.296817,"end_time":"2022-05-24T12:32:34.439238","exception":false,"start_time":"2022-05-24T12:32:34.142421","status":"completed"},"tags":[]},"source":["You can try to use additional features in the parameter X of pm.auto_arima to improve forecasting, but this will be done in other notebooks later."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:45.00503Z","iopub.status.busy":"2022-06-08T12:57:45.004772Z","iopub.status.idle":"2022-06-08T12:57:47.257378Z","shell.execute_reply":"2022-06-08T12:57:47.256384Z","shell.execute_reply.started":"2022-06-08T12:57:45.004999Z"},"papermill":{"duration":2.76505,"end_time":"2022-05-24T12:32:37.502198","exception":false,"start_time":"2022-05-24T12:32:34.737148","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%time\n","if is_ARIMA:\n","    # Automatic tuning of the ARIMA model \n","    model_auto = pm.auto_arima(train_ts['y'].values, \n","                               start_p=4,        # start p\n","                               start_q=4,        # start q\n","                               test='adf',       # use adftest to find optimal 'd'\n","                               max_p=5, max_q=5, # maximum p and q\n","                               m=1,              # frequency of series (1 - No Seasonality)\n","                               d=None,           # let model determine 'd'\n","                               seasonal=False,   # No Seasonality\n","                               start_P=0,        \n","                               D=0, \n","                               start_Q=0,\n","                               trace=True,\n","                               error_action='ignore',  \n","                               suppress_warnings=False, \n","                               stepwise=True     # use the stepwise algorithm outlined in Hyndman and Khandakar (2008) \n","                                                 # to identify the optimal model parameters. \n","                                                 # The stepwise algorithm can be significantly faster than fitting all \n","                                                 # hyper-parameter combinations and is less likely to over-fit the model\n","                              )\n","\n","    print(model_auto.summary())"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:47.259674Z","iopub.status.busy":"2022-06-08T12:57:47.259121Z","iopub.status.idle":"2022-06-08T12:57:47.286144Z","shell.execute_reply":"2022-06-08T12:57:47.285395Z","shell.execute_reply.started":"2022-06-08T12:57:47.259628Z"},"papermill":{"duration":0.325603,"end_time":"2022-05-24T12:32:38.186115","exception":false,"start_time":"2022-05-24T12:32:37.860512","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # Get orders of the best model from AutoARIMA\n","    arima_orders_best = list(model_auto.get_params().get('order'))\n","    print(f\"Optimal parameters are {arima_orders_best}\")\n","    model_auto = arima_fit(train_ts, 'y', order=(arima_orders_best[0],arima_orders_best[1],arima_orders_best[2]))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:47.289853Z","iopub.status.busy":"2022-06-08T12:57:47.288952Z","iopub.status.idle":"2022-06-08T12:57:48.069112Z","shell.execute_reply":"2022-06-08T12:57:48.068089Z","shell.execute_reply.started":"2022-06-08T12:57:47.289811Z"},"papermill":{"duration":0.897966,"end_time":"2022-05-24T12:32:39.387177","exception":false,"start_time":"2022-05-24T12:32:38.489211","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # Best model from AutoARIMA\n","    fig = model_auto.plot_diagnostics(figsize=(12,10))\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.301295,"end_time":"2022-05-24T12:32:39.997731","exception":false,"start_time":"2022-05-24T12:32:39.696436","status":"completed"},"tags":[]},"source":["- The residual errors seem fine with near zero mean and uniform variance."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:48.071128Z","iopub.status.busy":"2022-06-08T12:57:48.070622Z","iopub.status.idle":"2022-06-08T12:57:48.081209Z","shell.execute_reply":"2022-06-08T12:57:48.080522Z","shell.execute_reply.started":"2022-06-08T12:57:48.071079Z"},"papermill":{"duration":0.318671,"end_time":"2022-05-24T12:32:40.62494","exception":false,"start_time":"2022-05-24T12:32:40.306269","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_ARIMA:\n","    # Valid forecasting and save result\n","    result = arima_forecasting(result, model_auto, arima_orders_best, 'ARIMA_auto', valid_ts, 'valid')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.309715,"end_time":"2022-05-24T12:32:41.239647","exception":false,"start_time":"2022-05-24T12:32:40.929932","status":"completed"},"tags":[]},"source":["### 5.3. Other ML models (Multi-factors models) <a class=\"anchor\" id=\"5.3\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.300522,"end_time":"2022-05-24T12:32:41.84335","exception":false,"start_time":"2022-05-24T12:32:41.542828","status":"completed"},"tags":[]},"source":["This section provides examples of identifying the following models (but the list goes on):\n","* Linear Regression\n","* KNeighbors Regressor\n","* Support Vector Machines\n","* Linear SVR\n","* Random Forest Regressor\n","* Bagging Regressor\n","* XGB Regressor\n","* MLP Regressor\n","\n","Classic model XGBoost have a special format, but this notebook  uses its simplified version, which work in a data format similar to the models of the Sklearn library.\n","\n","Models based on neural networks (based on PyTorch or Keras) and ensembles of all these models are more effective, but this will be done later in other notebooks.\n","\n","**This section - from the notebook [Crypto - BTC : 7 prediction models](https://www.kaggle.com/code/vbmokin/crypto-btc-7-prediction-models)**"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:48.091378Z","iopub.status.busy":"2022-06-08T12:57:48.090447Z","iopub.status.idle":"2022-06-08T12:57:48.116022Z","shell.execute_reply":"2022-06-08T12:57:48.114999Z","shell.execute_reply.started":"2022-06-08T12:57:48.091337Z"},"papermill":{"duration":0.330565,"end_time":"2022-05-24T12:32:42.480812","exception":false,"start_time":"2022-05-24T12:32:42.150247","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get datasets\n","if is_other_ML:\n","    df2 = get_target_mf(df2, forecasting_days, col='Close')\n","    train_mf, ytrain_mf, valid_mf, yvalid_mf, test_mf, ytest_mf, train_valid_mf, y_train_valid_mf, starting_point = \\\n","                                    get_train_valid_test_mf(df2.copy(), forecasting_days, target='target')"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.305245,"end_time":"2022-05-24T12:32:43.091788","exception":false,"start_time":"2022-05-24T12:32:42.786543","status":"completed"},"tags":[]},"source":["#### **5.3.1. Set parameters for many models** <a class=\"anchor\" id=\"5.3.1\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.301646,"end_time":"2022-05-24T12:32:43.697589","exception":false,"start_time":"2022-05-24T12:32:43.395943","status":"completed"},"tags":[]},"source":["**TASK:** Try adding more models or changing the settings of these models."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:48.118139Z","iopub.status.busy":"2022-06-08T12:57:48.117636Z","iopub.status.idle":"2022-06-08T12:57:48.176533Z","shell.execute_reply":"2022-06-08T12:57:48.175487Z","shell.execute_reply.started":"2022-06-08T12:57:48.118101Z"},"papermill":{"duration":0.36441,"end_time":"2022-05-24T12:32:44.369898","exception":false,"start_time":"2022-05-24T12:32:44.005488","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["if is_other_ML:\n","    # Set parameters of models\n","    models = pd.DataFrame(columns = ['name', 'model', 'param_grid'])\n","\n","    # Linear Regression\n","    n = len(models)\n","    models.loc[n, 'name'] = 'Linear Regression'\n","    models.at[n, 'model'] = LinearRegression()\n","    models.at[n, 'param_grid'] = {'fit_intercept' : [True, False]}\n","\n","\n","    # KNeighbors Regressor\n","    n = len(models)\n","    models.loc[n, 'name'] = 'KNeighbors Regressor'\n","    models.at[n, 'model'] = KNeighborsRegressor()\n","    models.at[n, 'param_grid'] = {'n_neighbors': [3, 5, 10, 20, 30],\n","                                  'leaf_size': [10, 20, 30]\n","                                 }\n","\n","    # Support Vector Machines\n","    n = len(models)\n","    models.loc[n, 'name'] = 'Support Vector Machines'\n","    models.at[n, 'model'] = SVR()\n","    models.at[n, 'param_grid'] = {'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n","                                  'C': np.linspace(1, 15, 15),\n","                                  'tol': [1e-3, 1e-4]\n","                                 }\n","\n","    # Linear SVC\n","    n = len(models)\n","    models.loc[n, 'name'] = 'Linear SVR'\n","    models.at[n, 'model'] = LinearSVR()\n","    models.at[n, 'param_grid'] = {'C': np.linspace(1, 15, 15)}\n","\n","\n","    # Random Forest Classifier\n","    n = len(models)\n","    models.loc[n, 'name'] = 'Random Forest Regressor'\n","    models.at[n, 'model'] = RandomForestRegressor()\n","    models.at[n, 'param_grid'] = {'n_estimators': [40, 50, 60, 80], \n","                                  'min_samples_split': [30, 40, 50, 60], \n","                                  'min_samples_leaf': [10, 12, 15, 20, 50],\n","                                  'max_features': ['auto'], \n","                                  'max_depth': [3, 4, 5, 6]                   \n","                                 }\n","\n","    # Bagging Classifier\n","    n = len(models)\n","    models.loc[n, 'name'] = 'Bagging Regressor'\n","    models.at[n, 'model'] = BaggingRegressor()\n","    models.at[n, 'param_grid'] = {'max_features': np.linspace(0.05, 0.8, 1),\n","                                  'n_estimators': [3, 4, 5, 6],\n","                                  'warm_start' : [False]\n","                                 }\n","\n","    # XGB Classifier\n","    n = len(models)\n","    models.loc[n, 'name'] = 'XGB Regressor'\n","    models.at[n, 'model'] = xgb.XGBRegressor()\n","    models.at[n, 'param_grid'] = {'n_estimators': [50, 70, 90], \n","                                  'learning_rate': [0.01, 0.05, 0.1, 0.2],\n","                                  'max_depth': [3, 4, 5]\n","                                 }\n","\n","    # MLP Classifier\n","    n = len(models)\n","    models.loc[n, 'name'] = 'MLP Regressor'\n","    models.at[n, 'model'] = MLPRegressor()\n","    models.at[n, 'param_grid'] = {'hidden_layer_sizes': [i for i in range(2,5)],\n","                                  'solver': ['lbfgs', 'sgd'],\n","                                  'learning_rate': ['adaptive'],\n","                                  'learning_rate_init': [0.001, 0.01],\n","                                  'max_iter': [1000]\n","                                 }\n","models"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.332771,"end_time":"2022-05-24T12:32:45.010099","exception":false,"start_time":"2022-05-24T12:32:44.677328","status":"completed"},"tags":[]},"source":["#### **5.3.2. Models training and forecasting** <a class=\"anchor\" id=\"5.3.2\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:48.179165Z","iopub.status.busy":"2022-06-08T12:57:48.178036Z","iopub.status.idle":"2022-06-08T12:57:48.191053Z","shell.execute_reply":"2022-06-08T12:57:48.189995Z","shell.execute_reply.started":"2022-06-08T12:57:48.179116Z"},"papermill":{"duration":0.324144,"end_time":"2022-05-24T12:32:45.638667","exception":false,"start_time":"2022-05-24T12:32:45.314523","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def model_prediction(result, models, train_features, valid_features, train_labels, valid_labels):    \n","    # Models training and data prediction for all models from DataFrame models\n","    # Saving results for validation dataset into dataframe result\n","    \n","    def calc_add_score(res, n, type_score, list_true, list_pred, feature_end):\n","        # Calculation score with type=type_score for list_true and list_pred \n","        # Adding score into res.loc[n,...]\n","        res.loc[i, type_score + feature_end] = calc_metrics(type_score, list_true, list_pred)\n","        return res\n","    \n","    # Results\n","    model_all = []\n","\n","    for i in range(len(models)):\n","        # Training\n","        print(f\"Tuning model '{models.loc[i, 'name']}'\")\n","        model = GridSearchCV(models.at[i, 'model'], models.at[i, 'param_grid'])\n","        model.fit(train_features, train_labels)\n","        model_all.append(model)\n","        print(f\"Best parameters: {model.best_params_}\\n\")\n","        \n","        # Prediction\n","        ypred = model.predict(valid_features)\n","        \n","        # Scoring and saving results into the main dataframe result\n","        n = len(result)\n","        result.loc[n,'name_model'] = f\"{models.loc[i, 'name']}\"\n","        result.loc[n,'type_data'] = \"valid\"\n","        result.at[n,'params'] = model.best_params_\n","        result.at[n,'ypred'] = ypred\n","        #result = result_add_metrics(result, n, valid_labels, valid_pred)\n","        \n","    return result, model_all"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T12:57:48.193162Z","iopub.status.busy":"2022-06-08T12:57:48.192431Z","iopub.status.idle":"2022-06-08T13:04:12.982381Z","shell.execute_reply":"2022-06-08T13:04:12.981393Z","shell.execute_reply.started":"2022-06-08T12:57:48.193124Z"},"papermill":{"duration":377.842417,"end_time":"2022-05-24T12:39:03.782367","exception":false,"start_time":"2022-05-24T12:32:45.93995","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["%%time\n","if is_other_ML:\n","    # Models tuning and the forecasting\n","    result, model_all = model_prediction(result, models, train_mf, valid_mf, ytrain_mf, yvalid_mf)"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.306427,"end_time":"2022-05-24T12:39:04.402835","exception":false,"start_time":"2022-05-24T12:39:04.096408","status":"completed"},"tags":[]},"source":["### 5.4. Choosing the main optimal model and forecasting <a class=\"anchor\" id=\"5.4\"></a>"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:12.98469Z","iopub.status.busy":"2022-06-08T13:04:12.984158Z","iopub.status.idle":"2022-06-08T13:04:12.990324Z","shell.execute_reply":"2022-06-08T13:04:12.989692Z","shell.execute_reply.started":"2022-06-08T13:04:12.984642Z"},"papermill":{"duration":0.320791,"end_time":"2022-05-24T12:39:05.039192","exception":false,"start_time":"2022-05-24T12:39:04.718401","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def recovery_prediction(y, starting_point):\n","    # Recovering prediction of multi-factors model for shifted col_diff to col in the dataframe df\n","    # y has type np.array\n","    # starting_point is dictionary with start values for the recovering data\n","    # Returns y (np.array) with recovering data\n","    \n","    return np.insert(y, 0, starting_point).cumsum()[1:]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:12.99222Z","iopub.status.busy":"2022-06-08T13:04:12.991975Z","iopub.status.idle":"2022-06-08T13:04:13.006578Z","shell.execute_reply":"2022-06-08T13:04:13.005546Z","shell.execute_reply.started":"2022-06-08T13:04:12.99219Z"},"papermill":{"duration":0.322481,"end_time":"2022-05-24T12:39:05.663547","exception":false,"start_time":"2022-05-24T12:39:05.341066","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def result_recover_and_metrics(result, df_ts, type_data, start_points):\n","    # Recovering prediction: from shifted_Close_diff to Close\n","    # Calculation metrics for recovering ypred forecasting for all models in result\n","    # ypred real is from df_ts['y']\n","    # start points value for the recovering is from dictionary start_points\n","    # type_data = 'valid' or 'test'\n","\n","    for i in range(len(result)):\n","        if (result.loc[i, 'type_data']==type_data) and (result.loc[i, 'mape'] is np.nan):\n","            ypred = result.loc[i, 'ypred']\n","\n","            # Recovering ypred for multi-factors models\n","            if not (str(result.loc[i, 'type_model']) in ['Prophet', 'ARIMA']):\n","                # Multi-factors model\n","                # Get start points value for the recovering\n","                start_point_value = start_points['valid_start_point'] if type_data=='valid' else start_points['test_start_point']\n","                # Recovering prediction\n","                ypred = recovery_prediction(ypred, start_point_value)            \n","\n","            # Calculation metrics\n","            result = result_add_metrics(result, i, df_ts['y'], ypred)\n","    \n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.008365Z","iopub.status.busy":"2022-06-08T13:04:13.00811Z","iopub.status.idle":"2022-06-08T13:04:13.09788Z","shell.execute_reply":"2022-06-08T13:04:13.097228Z","shell.execute_reply.started":"2022-06-08T13:04:13.008335Z"},"papermill":{"duration":0.401246,"end_time":"2022-05-24T12:39:06.371773","exception":false,"start_time":"2022-05-24T12:39:05.970527","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Dispay and save all results for validation dataset\n","if len(result) > 0:\n","    \n","    # Get type of each model\n","    result['type_model'] = result['name_model'].str.split('_').str[0]\n","\n","    # Calculation metrics for recovering prediction ypred for validation dataset by all models \n","    result = result_recover_and_metrics(result, valid_ts, 'valid', starting_point)\n","    display(result[['name_model', 'type_data', 'r2_score', 'rmse', 'mape']].sort_values(by=['type_data', 'mape', 'rmse'], ascending=True))\n","    \n","    # Save results\n","    num_models = len(result[result['type_data']=='valid']['name_model'].unique().tolist())\n","    print(f\"Number of models built - {num_models}\")\n","    result.to_csv(f'result_of_{num_models}_models_for_forecasting_days_{forecasting_days}.csv')\n","else: \n","    print('There are no tuned models!')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.09949Z","iopub.status.busy":"2022-06-08T13:04:13.0991Z","iopub.status.idle":"2022-06-08T13:04:13.107738Z","shell.execute_reply":"2022-06-08T13:04:13.107033Z","shell.execute_reply.started":"2022-06-08T13:04:13.099454Z"},"papermill":{"duration":0.317888,"end_time":"2022-05-24T12:39:07.000081","exception":false,"start_time":"2022-05-24T12:39:06.682193","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_model_opt(name_model, params):\n","    # Model tuning for the name_model\n","    \n","    print(name_model)\n","    if name_model=='Linear Regression':\n","        model = LinearRegression(**params)\n","        \n","    elif name_model=='KNeighbors Regressor':\n","        model = KNeighborsRegressor(**params)\n","        \n","    elif name_model=='Support Vector Machines':\n","        model = SVR(**params)\n","        \n","    elif name_model=='Linear SVR':\n","        model = LinearSVR(**params)\n","        \n","    elif name_model=='Random Forest Regressor':\n","        model = RandomForestRegressor(**params)\n","        \n","    elif name_model=='Bagging Regressor':\n","        model = BaggingRegressor(**params)\n","    \n","    elif name_model=='MLP Regressor':\n","        model = MLPRegressor(**params)\n","        \n","    elif name_model=='XGB Regressor':\n","        model = xgb.XGBRegressor(**params)\n","        \n","    else: model = None\n","        \n","    return model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.110488Z","iopub.status.busy":"2022-06-08T13:04:13.109537Z","iopub.status.idle":"2022-06-08T13:04:13.12679Z","shell.execute_reply":"2022-06-08T13:04:13.125613Z","shell.execute_reply.started":"2022-06-08T13:04:13.110448Z"},"papermill":{"duration":0.326684,"end_time":"2022-05-24T12:39:07.638596","exception":false,"start_time":"2022-05-24T12:39:07.311912","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_params_optimal_model(result, main_metrics):\n","    # Get parameters of the optimal model from dataframe result by main_metrics\n","\n","    # Set the data type to float (just in case)\n","    result[main_metrics] = result[main_metrics].astype('float')\n","    \n","    # Choose the optimal model\n","    opt_result = result[result['type_data']=='valid'].reset_index(drop=True)\n","    if main_metrics=='r2_score':\n","        opt_model = opt_result.nlargest(1, main_metrics)\n","    else:\n","        # 'mape' or 'rmse'\n","        opt_model = opt_result.nsmallest(1, main_metrics)\n","    display(opt_model[['name_model', 'r2_score', 'rmse', 'mape', 'params']])\n","\n","    # Get parameters of the optimal model\n","    opt_name_model = opt_model['name_model'].tolist()[0]\n","    opt_type_model = opt_model['type_model'].tolist()[0]\n","    opt_params_model = opt_model['params'].tolist()[0]\n","    print(f'Optimal model by metrics \"{main_metrics}\" is \"{opt_name_model}\" with type \"{opt_type_model}\" parameters {opt_params_model}')\n","    \n","    return opt_name_model, opt_type_model, opt_params_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.128637Z","iopub.status.busy":"2022-06-08T13:04:13.128212Z","iopub.status.idle":"2022-06-08T13:04:13.144749Z","shell.execute_reply":"2022-06-08T13:04:13.143983Z","shell.execute_reply.started":"2022-06-08T13:04:13.128603Z"},"papermill":{"duration":0.332731,"end_time":"2022-05-24T12:39:08.285037","exception":false,"start_time":"2022-05-24T12:39:07.952306","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def model_training_forecasting(result, df, y, test, ytest,  \n","                               name_model, type_model, params, type_test='1'):\n","    # Model training for df and y\n","    # Forecasting ypred\n","    # type_model = 'Prophet' or \"ARIMA\" or 'Other ML'\n","    # type_test = '1' (with find optimal parameters by GridSearchCV) \n","    # type_test = '2' (with optimal parameters - without GridSearchCV)\n","    # return params and metrics in the dataframe result\n","    \n","    if type_model=='Prophet':    \n","        season_days_optimal = params[0]\n","        fourier_order_seasonality_optimal = params[1]\n","        model_opt = None\n","        _, ypred = prophet_modeling(result, \n","                                    cryptocurrency, \n","                                    df, \n","                                    test, \n","                                    holidays_df, \n","                                    season_days_optimal,\n","                                    fourier_order_seasonality_optimal,\n","                                    forecasting_days,\n","                                    f'{type_model}_optimal',\n","                                    'test')        \n","    elif type_model=='ARIMA':\n","        season_days_optimal = params[0]\n","        fourier_order_seasonality_optimal = params[1]        \n","        model_opt = None\n","        \n","        # Training ARIMA optimal model for training+valid dataset\n","        df['y'] = y\n","        model_opt = arima_fit(df, 'y', order=(params[0],params[1],params[2]))        \n","\n","        # Model diagnostics\n","        fig = model_opt.plot_diagnostics(figsize=(12,10))\n","        plt.show()\n","\n","        # Plot residual errors\n","        get_residual_errors(model_opt)\n","\n","        # Test forecasting and save result\n","        ypred = model_opt.forecast(steps=len(test))        \n","\n","    else:\n","        # Other ML model\n","        # Training ML optimal model for training+valid dataset\n","        print(f\"Tuning model '{name_model}'\")\n","        models_opt_number = models[models['name']==name_model].index.tolist()[0]\n","        #print(f\"Model - {models.at[models_opt_number,'model']} with parameters {params}\")\n","        if type_test=='1':\n","            model_opt = GridSearchCV(models.at[models_opt_number,'model'], models.at[models_opt_number,'param_grid'])\n","        else:\n","            # type_test=='2'\n","            model_opt = get_model_opt(models.at[models_opt_number,'name'], params)\n","        model_opt.fit(df, y)\n","        \n","        # Forecasting\n","        ypred = model_opt.predict(test)\n","\n","        \n","    # Scoring and saving results into the dataframe result\n","    n = len(result)-1\n","    result.loc[n,'name_model'] = f\"{type_model}_optimal\"\n","    result.loc[n,'type_data'] = \"test\"\n","    result.loc[n,'type_model'] = type_model\n","    result.at[n,'params'] = params\n","    result.at[n,'ypred'] = ypred\n","    #result = result_add_metrics(result, n, ytest, ypred)\n","    \n","    return result, model_opt, ypred"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.146442Z","iopub.status.busy":"2022-06-08T13:04:13.146002Z","iopub.status.idle":"2022-06-08T13:04:13.163342Z","shell.execute_reply":"2022-06-08T13:04:13.162271Z","shell.execute_reply.started":"2022-06-08T13:04:13.146403Z"},"papermill":{"duration":0.325662,"end_time":"2022-05-24T12:39:10.259386","exception":false,"start_time":"2022-05-24T12:39:09.933724","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["def get_optimal_model_and_forecasting(result, main_metrics, start_points):\n","    # Choosion the optimal model from dataframe result by main_metrics\n","    # Tuning optimal model for big dataset train+valid \n","    # Test forecasting and drawing it\n","    # Returns the optimal model and it's name\n","\n","    \n","    if len(result) > 0:\n","        # Get parameters of the optimal model from dataframe result by main_metrics\n","        opt_name_model, opt_type_model, opt_params_model = get_params_optimal_model(result, \n","                                                                                    main_metrics)\n","        # Set datasets for the final tuning and testing by optimal model\n","        if (opt_type_model=='Prophet') or (opt_type_model=='ARIMA'):\n","            train_valid = train_valid_ts.copy()\n","            y_train_valid = train_valid_ts['y'].copy()\n","            test = test_ts.copy()\n","            ytest = test_ts['y'].copy()\n","            \n","        else:\n","            # Multi-factors ML models\n","            train_valid = train_valid_mf.copy()\n","            y_train_valid = y_train_valid_mf.copy()\n","            test = test_mf.copy()\n","            ytest = ytest_mf.copy()\n","    \n","        # Optimal model training for train+valid and test forecasting\n","        result, model_opt, ypred = model_training_forecasting(result, train_valid, y_train_valid,\n","                                                              test, ytest,\n","                                                              opt_name_model, opt_type_model, \n","                                                              opt_params_model, '1')\n","        \n","        # Calculation metrics for recovering prediction ypred for test dataset by the optimal model\n","        result = result_recover_and_metrics(result, test_ts, 'test', start_points)\n","        \n","        # Drawing plot for prediction for the test data \n","        if not ((opt_type_model=='Prophet') or (opt_type_model=='ARIMA')):\n","            # Recovery values \"Close\"\n","            ytest_plot = recovery_prediction(ytest.values, start_points['test_start_point'])\n","            ypred_plot = recovery_prediction(ypred, start_points['test_start_point'])\n","        else:\n","            ytest_plot = ytest.copy()\n","            ypred_plot = ypred.copy()\n","            \n","        # Drawing \n","        plt.figure(figsize=(12,8))\n","        x = np.arange(len(ytest_plot))\n","        plt.scatter(x, ytest_plot, label = \"Target test data\", color = 'g', s=100)\n","        plt.scatter(x, ypred_plot, label = f\"{opt_name_model} forecasting\", color = 'r', s=50)\n","        plt.title(f'Forecasting of test data using the \"{opt_name_model}\" model, which is optimal for \"{main_metrics}\" metrics')\n","        plt.ylim(0)\n","        plt.legend(loc='lower right')\n","        plt.grid(True)\n","        \n","        return opt_name_model"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.164808Z","iopub.status.busy":"2022-06-08T13:04:13.164471Z","iopub.status.idle":"2022-06-08T13:04:13.215434Z","shell.execute_reply":"2022-06-08T13:04:13.214554Z","shell.execute_reply.started":"2022-06-08T13:04:13.16478Z"},"trusted":true},"outputs":[],"source":["result"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:13.216934Z","iopub.status.busy":"2022-06-08T13:04:13.216624Z","iopub.status.idle":"2022-06-08T13:04:24.654767Z","shell.execute_reply":"2022-06-08T13:04:24.653796Z","shell.execute_reply.started":"2022-06-08T13:04:13.216874Z"},"papermill":{"duration":92.211978,"end_time":"2022-05-24T12:40:42.778723","exception":false,"start_time":"2022-05-24T12:39:10.566745","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Get the optimal model by different metrics\n","if len(result) > 0:\n","    for valid_metrics in ['r2_score', 'rmse', 'mape']:\n","        get_optimal_model_and_forecasting(result, valid_metrics, starting_point)    "]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.317769,"end_time":"2022-05-24T12:40:43.417273","exception":false,"start_time":"2022-05-24T12:40:43.099504","status":"completed"},"tags":[]},"source":["### 5.5. Feature importance study <a class=\"anchor\" id=\"5.5\"></a>"]},{"cell_type":"markdown","metadata":{"papermill":{"duration":0.323868,"end_time":"2022-05-24T12:40:44.065405","exception":false,"start_time":"2022-05-24T12:40:43.741537","status":"completed"},"tags":[]},"source":["A feature importance study is performed for the best of the \"non ime Series\" models, as no additional features were used in the Time Series models."]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:24.656141Z","iopub.status.busy":"2022-06-08T13:04:24.655915Z","iopub.status.idle":"2022-06-08T13:04:24.740493Z","shell.execute_reply":"2022-06-08T13:04:24.739482Z","shell.execute_reply.started":"2022-06-08T13:04:24.656113Z"},"papermill":{"duration":0.433131,"end_time":"2022-05-24T12:40:44.820765","exception":false,"start_time":"2022-05-24T12:40:44.387634","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Training ML optimal model for training+valid dataset\n","# Get parameters of the optimal model from dataframe result (without Time Series models) by main_metrics\n","if is_other_ML:\n","    main_metrics = 'r2_score'\n","    if (len(result) > 0) and (len(models) > 0):\n","        result_nonTS = result[(result['type_model']!='Prophet') & (result['type_model']!='ARIMA')].reset_index(drop=True)\n","        opt_name_model2, opt_type_model2, opt_params_model2 = get_params_optimal_model(result_nonTS, \n","                                                                                main_metrics)\n","\n","        result, model_opt, ypred = model_training_forecasting(result, \n","                                                              train_valid_mf, \n","                                                              y_train_valid_mf,\n","                                                              test_mf, \n","                                                              ytest_mf,\n","                                                              opt_name_model2, \n","                                                              opt_type_model2, \n","                                                              opt_params_model2, \n","                                                              '2')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:24.74204Z","iopub.status.busy":"2022-06-08T13:04:24.7418Z","iopub.status.idle":"2022-06-08T13:04:24.747242Z","shell.execute_reply":"2022-06-08T13:04:24.746307Z","shell.execute_reply.started":"2022-06-08T13:04:24.742012Z"},"trusted":true},"outputs":[],"source":["# All features names\n","if is_other_ML:\n","    coeff = pd.DataFrame(train_valid_mf.columns)\n","    coeff.columns = ['feature']"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:24.749712Z","iopub.status.busy":"2022-06-08T13:04:24.748755Z","iopub.status.idle":"2022-06-08T13:04:24.761942Z","shell.execute_reply":"2022-06-08T13:04:24.761213Z","shell.execute_reply.started":"2022-06-08T13:04:24.74966Z"},"trusted":true},"outputs":[],"source":["def add_fi_coeff(coeff, col, list_new_fi_coeff=None, df_new_fi_coeff=None):\n","    # Adds new importance of features as feature col\n","    # from list list_new_fi_coeff or dataframe df_new_fi_coeff\n","    # to the resulting dataframe coeff with feature names \n","    # Missed importance values are replaced by zero\n","    \n","    if list_new_fi_coeff is not None:\n","        df_new_fi_coeff = coeff[['feature']].copy()\n","        df_new_fi_coeff[\"score\"] = pd.Series(list_new_fi_coeff)\n","    \n","    if df_new_fi_coeff is not None:\n","        # Rename df_new_fi_coeff\n","        df_new_fi_coeff.columns = ['feature', 'score']   # to the plot drawing\n","        df_new_fi_coeff[col] = df_new_fi_coeff['score']  # to the merging and saving\n","        \n","        # Merging dataframes - coeff of all features with new_fi_coeff\n","        coeff = coeff.merge(df_new_fi_coeff[['feature', col]], on='feature', how='left').fillna(0)\n","        \n","        is_score = True\n","    else:\n","        print(f'Data is absent fol {col}')\n","        is_score = False\n","        coeff = None\n","    \n","    return coeff, df_new_fi_coeff, is_score"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:04:24.763972Z","iopub.status.busy":"2022-06-08T13:04:24.763177Z","iopub.status.idle":"2022-06-08T13:05:17.758958Z","shell.execute_reply":"2022-06-08T13:05:17.757197Z","shell.execute_reply.started":"2022-06-08T13:04:24.763933Z"},"trusted":true},"outputs":[],"source":["# Feature importance diagram with SHAP\n","if is_other_ML:\n","    if (len(result) > 0) and (len(models) > 0):\n","        print('Feature importance diagram with SHAP:')\n","        try:\n","            # Trees\n","            explainer = shap.TreeExplainer(model_opt)\n","            shap_values = explainer.shap_values(test_mf)\n","            shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n","            shap.summary_plot(shap_values, test_mf)\n","\n","            # Save permutation feature importance values\n","            coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', shap_values)\n","        except: \n","            try:\n","                # Other types of models\n","                explainer = shap.KernelExplainer(model_opt.predict, train_valid_mf)\n","                shap_values = explainer.shap_values(test_mf)\n","\n","                # Plot drawing\n","                shap.summary_plot(shap_values, test_mf, plot_type=\"bar\", feature_names=coeff['feature'].tolist())\n","                shap.summary_plot(shap_values, test_mf)\n","\n","                # Get feature importance values from shap_values format\n","                # Thanks to https://stackoverflow.com/a/69523421/12301574\n","                shap_values_all = pd.DataFrame(shap_values, columns = test_mf.columns)\n","                vals = np.abs(shap_values_all.values).mean(0)\n","                shap_importance = pd.DataFrame(list(zip(test_mf.columns, vals)),\n","                                                  columns=['feature','score'])            \n","\n","                # Saving feature importance values\n","                coeff, _, is_SHAP_successfully = add_fi_coeff(coeff, 'shap_fi_score', None, shap_importance)            \n","\n","            except: \n","                is_SHAP_successfully = False\n","\n","        if not is_SHAP_successfully:\n","            print('Feature importance diagram for this optimal model is not supported in SHAP')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:05:17.760806Z","iopub.status.busy":"2022-06-08T13:05:17.760562Z","iopub.status.idle":"2022-06-08T13:05:18.944049Z","shell.execute_reply":"2022-06-08T13:05:18.943034Z","shell.execute_reply.started":"2022-06-08T13:05:17.760778Z"},"trusted":true},"outputs":[],"source":["# Force plot - Feature importance diagram with SHAP for the certaion row in test_mf\n","if is_other_ML:\n","    if (len(result) > 0) and (len(models) > 0):\n","        row_number_in_test_mf = 0\n","        print('Feature importance diagram as the Force plot with SHAP:')\n","        if is_SHAP_successfully:\n","            shap.initjs()\n","            shap.force_plot(explainer.expected_value, shap_values[0,:], \n","                            test_mf.loc[test_mf.index.tolist()[row_number_in_test_mf],:],\n","                            feature_names=coeff['feature'].tolist(),\n","                            matplotlib=True, show=False)\n","            plt.savefig('force_plot.png')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:05:18.946499Z","iopub.status.busy":"2022-06-08T13:05:18.945614Z","iopub.status.idle":"2022-06-08T13:05:19.180109Z","shell.execute_reply":"2022-06-08T13:05:19.179241Z","shell.execute_reply.started":"2022-06-08T13:05:18.946455Z"},"trusted":true},"outputs":[],"source":["# Creation and drawing the feature importance diagrams\n","if is_other_ML:\n","    if (len(result) > 0) and (len(models) > 0):\n","\n","        # Coefficients\n","        if opt_name_model2=='XGB Regressor':\n","            print('Feature importance diagram')\n","            # Coef. of the feature with nonzero importance\n","            xgb_coeff = pd.DataFrame.from_dict(model_opt.get_booster().get_score(importance_type='weight'), orient='index').reset_index(drop=False)\n","            coeff, _, is_score = add_fi_coeff(coeff, 'xgb_fi_coeff', None, xgb_coeff)\n","\n","            # With the library xgboost\n","            fig =  plt.figure(figsize = (15,15))\n","            axes = fig.add_subplot(111)\n","            xgb.plot_importance(model_opt,ax = axes,height = 0.5)\n","            plt.show()\n","            plt.close()\n","\n","        else:\n","            # With the library sklearn\n","            try:\n","                coef_model = model_opt.coef_\n","                coeff, coeff_new, is_score = add_fi_coeff(coeff, 'lr_fi_score', coef_model)\n","            except:\n","                try:\n","                    coef_model = feature_importances_\n","                    coeff, coeff_new, is_score = add_fi_coeff(coeff, 'model_fi_score', coef_model)\n","                except: \n","                    print('The importance of the feature could not be obtained')\n","                    is_score = False\n","\n","            if is_score:\n","                # Plot drawing\n","                coeff_non_zero = coeff_new[coeff_new['score']>0]\n","                plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n","                coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n","                plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n","                plt.title(\"Feature importance diagram\")\n","                plt.axvline(x=0, color=\".5\")\n","                plt.xlabel(\"Coefficient values\")\n","                plt.subplots_adjust(left=0.3)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:05:19.181823Z","iopub.status.busy":"2022-06-08T13:05:19.181471Z","iopub.status.idle":"2022-06-08T13:05:21.207964Z","shell.execute_reply":"2022-06-08T13:05:21.207108Z","shell.execute_reply.started":"2022-06-08T13:05:19.181793Z"},"trusted":true},"outputs":[],"source":["# Permutation feature importance diagram\n","if is_other_ML:\n","    if (len(result) > 0) and (len(models) > 0):\n","        try:\n","            perm_importance = permutation_importance(model_opt, test_mf, ytest_mf)\n","\n","            # Save permutation feature importance values\n","            coef_model = perm_importance.importances_mean\n","            coeff, coeff_new, is_score = add_fi_coeff(coeff, 'perm_fi_score', coef_model)\n","\n","            print('Permutation feature importance diagram:') \n","            coeff_non_zero = coeff_new[coeff_new['score'].abs()>1e-4]\n","            coeff_non_zero = coeff_non_zero.sort_values(by='score', ascending=True)\n","            plt.figure(figsize=(12, int(len(coeff_non_zero)*0.4)))\n","            plt.barh(coeff_non_zero[\"feature\"], coeff_non_zero[\"score\"])\n","            plt.xlabel(\"Permutation Importance\")\n","            plt.show()\n","            is_perm_importance = True\n","        except: print('Permutation feature importance diagram for this optimal model is not supported')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:05:21.21074Z","iopub.status.busy":"2022-06-08T13:05:21.209522Z","iopub.status.idle":"2022-06-08T13:05:21.940358Z","shell.execute_reply":"2022-06-08T13:05:21.939437Z","shell.execute_reply.started":"2022-06-08T13:05:21.210685Z"},"trusted":true},"outputs":[],"source":["# Feature importance diagram with ELI5\n","if is_other_ML:\n","    if (len(result) > 0) and (len(models) > 0):\n","        try:\n","            print('Feature importance diagram with ELI5:')\n","            perm = PermutationImportance(model_opt).fit(test_mf,ytest_mf)\n","\n","            # Save permutation feature importance values\n","            coef_model = perm.feature_importances_  # Feature importances, \n","                                                    # computed as mean decrease \n","                                                    # of the score when a feature \n","                                                    # is permuted (i.e. becomes noise)\n","            coeff, _, is_score = add_fi_coeff(coeff, 'eli5_perm_fi_score', coef_model)\n","\n","            # Display permutation feature importance values with ELI5\n","            display(eli5.show_weights(perm, feature_names = coeff.feature.tolist()))\n","\n","        except: print('Feature importance diagram for this optimal model is not supported in ELI5')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2022-06-08T13:05:21.942331Z","iopub.status.busy":"2022-06-08T13:05:21.94196Z","iopub.status.idle":"2022-06-08T13:05:21.972225Z","shell.execute_reply":"2022-06-08T13:05:21.971434Z","shell.execute_reply.started":"2022-06-08T13:05:21.942266Z"},"papermill":{"duration":0.33325,"end_time":"2022-05-24T12:40:45.469563","exception":false,"start_time":"2022-05-24T12:40:45.136313","status":"completed"},"tags":[],"trusted":true},"outputs":[],"source":["# Display and saving features importance values\n","if is_other_ML:\n","    if coeff.isna().sum().sum()==0:\n","        print('Feature importance values:')\n","        fi_cols = coeff.columns.tolist()[1:]\n","        if len(fi_cols) > 0:\n","            coeff = coeff.sort_values(by=fi_cols, ascending=False)\n","            display(coeff)\n","        coeff.to_csv(f'feature_importance_for_optimal_model_{opt_name_model2}.csv', index=False)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.4"}},"nbformat":4,"nbformat_minor":4}
